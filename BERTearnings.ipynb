{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/col-a-guo/guo_chen_jang_ms_project/blob/main/BERTearnings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMT74j2CWx4V"
      },
      "outputs": [],
      "source": [
        "!pip install torch transformers datasets torchmetrics scikit-learn numpy huggingface-hub pandas imblearn pytorch_metric_learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "qfI3GWR8L08v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QRwF2e0Jfmh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "FILE_PATH = '/content/drive/MyDrive/BERTearningsdata/'\n",
        "print(os.listdir('/content/drive/MyDrive/BERTearningsdata/'))"
      ],
      "metadata": {
        "id": "sSCWyzOyMlYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from transformers import get_scheduler\n",
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "import torchmetrics\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import random\n",
        "import numpy as np\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from torch.optim.lr_scheduler import LambdaLR, ExponentialLR\n",
        "import os\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    seed_value = 1\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "    version_list = [\"bottleneckBERT\"]\n",
        "    # Default hyperparameters\n",
        "    default_lr = 2e-5\n",
        "    target_lr = 9e-6\n",
        "    default_eps = 6.748313060587885e-08\n",
        "    default_batch_size = 32\n",
        "    num_epochs = 200\n",
        "    patience = 10\n",
        "    warmup_proportion = 0.2\n",
        "    focal_weight = 0\n",
        "    focal_alpha = 0.25\n",
        "    focal_gamma = 2.0\n",
        "\n",
        "    # function to generate classification report for binary classification\n",
        "    def generate_classification_report(model, dataloader, num_classes, epoch=None, version=None, split_name=\"Test\", model_name=\"\"):\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                input_ids, attention_mask, features, Bottid_encoded, labels = [t.to(device) for t in batch]\n",
        "                logits, _ = model(input_ids, attention_mask, features, Bottid_encoded)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        all_preds = np.array(all_preds)\n",
        "        all_labels = np.array(all_labels)\n",
        "\n",
        "        report = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(num_classes)], digits=4)\n",
        "\n",
        "        cm = confusion_matrix(all_labels, all_preds, labels=list(range(num_classes)))\n",
        "        cm_report = \"\\nConfusion Matrix:\\n\"\n",
        "        cm_report += \"            Predicted\\n\"\n",
        "        cm_report += \"           \" + \"    \".join(map(str, range(num_classes))) + \"\\n\"\n",
        "        cm_report += \"Actual\\n\"\n",
        "        for i, row in enumerate(cm):\n",
        "            cm_report += f\"      {i}   \" + \"    \".join(map(str, row)) + \"\\n\"\n",
        "\n",
        "        final_report = f\"\"\"\n",
        "    Classification Report ({split_name}, Version: {version}, Epoch {epoch if epoch is not None else 'Final'}):\\n\n",
        "    {report}\\n\n",
        "    {cm_report}\n",
        "    \"\"\"\n",
        "\n",
        "        print(final_report)\n",
        "        with open(f\"classification_report_{model_name}.txt\", \"a\") as f:\n",
        "            f.write(final_report + \"\\n\")\n",
        "\n",
        "        f1 = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(num_classes)], output_dict=True, zero_division=0)['weighted avg']['f1-score']\n",
        "\n",
        "        return f1, all_preds, all_labels\n",
        "\n",
        "    def create_test_sets(test_dataset, num_sets=10, subset_size=0.9, num_classes=2):\n",
        "        \"\"\"\n",
        "        Splits the test set into `num_sets` subsets for binary classification\n",
        "        \"\"\"\n",
        "        # Get indices of samples for each label\n",
        "        label_indices = {}\n",
        "        for label_idx in range(num_classes):\n",
        "            label_indices[label_idx] = [i for i, item in enumerate(test_dataset) if item[-1] == label_idx]\n",
        "\n",
        "        # Calculate the number of samples to select for each label in each subset\n",
        "        num_samples_per_label = {label_idx: int(len(indices) * subset_size)\n",
        "                                  for label_idx, indices in label_indices.items()}\n",
        "\n",
        "        test_sets = []\n",
        "        for _ in range(num_sets):\n",
        "            subset_indices = []\n",
        "            for label_idx in range(num_classes):\n",
        "                subset_label_indices = random.sample(label_indices[label_idx], num_samples_per_label[label_idx])\n",
        "                subset_indices.extend(subset_label_indices)\n",
        "\n",
        "            random.shuffle(subset_indices)\n",
        "            subset = Subset(test_dataset, subset_indices)\n",
        "            test_sets.append(subset)\n",
        "\n",
        "        return test_sets\n",
        "\n",
        "    def evaluate_on_multiple_test_sets(model, test_sets, num_classes=2, version=None, model_name=\"\"):\n",
        "        \"\"\"\n",
        "        Evaluates the model on multiple test sets and calculates the average performance and standard deviations.\n",
        "        \"\"\"\n",
        "        all_reports = []\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        for i, test_set in enumerate(test_sets):\n",
        "            dataloader = DataLoader(test_set, batch_size=default_batch_size)\n",
        "            f1, preds, labels = generate_classification_report(model, dataloader, num_classes, version=version, split_name=f\"Test Set {i+1}\", model_name=model_name)\n",
        "            all_reports.append(classification_report(labels, preds, target_names=[str(i) for i in range(num_classes)], output_dict=True, zero_division=0))\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "        metrics = {}\n",
        "        for class_idx in range(num_classes):\n",
        "            class_str = str(class_idx)\n",
        "            metrics[f'precision_{class_str}'] = [report[class_str]['precision'] for report in all_reports]\n",
        "            metrics[f'recall_{class_str}'] = [report[class_str]['recall'] for report in all_reports]\n",
        "            metrics[f'f1-score_{class_str}'] = [report[class_str]['f1-score'] for report in all_reports]\n",
        "            metrics[f'support_{class_str}'] = [report[class_str]['support'] for report in all_reports]\n",
        "\n",
        "        metrics['macro_avg_precision'] = [report['macro avg']['precision'] for report in all_reports]\n",
        "        metrics['macro_avg_recall'] = [report['macro avg']['recall'] for report in all_reports]\n",
        "        metrics['macro_avg_f1-score'] = [report['macro avg']['f1-score'] for report in all_reports]\n",
        "        metrics['macro_avg_support'] = [report['macro avg']['support'] for report in all_reports]\n",
        "\n",
        "        metrics['weighted_avg_precision'] = [report['weighted avg']['precision'] for report in all_reports]\n",
        "        metrics['weighted_avg_recall'] = [report['weighted avg']['recall'] for report in all_reports]\n",
        "        metrics['weighted_avg_f1-score'] = [report['weighted avg']['f1-score'] for report in all_reports]\n",
        "        metrics['weighted_avg_support'] = [report['weighted avg']['support'] for report in all_reports]\n",
        "\n",
        "        results = {}\n",
        "        for metric_name, values in metrics.items():\n",
        "            results[metric_name + \"_avg\"] = np.mean(values)\n",
        "            results[metric_name + \"_std\"] = np.std(values)\n",
        "\n",
        "        final_report = \"Averaged performance across all test sets:\\n\"\n",
        "        for metric_name, value in results.items():\n",
        "            if \"_avg\" in metric_name:\n",
        "                std_name = metric_name.replace(\"_avg\", \"_std\")\n",
        "                if std_name in results:\n",
        "                    final_report += f\"{metric_name}: {value:.4f} +/- {results[std_name]:.4f}\\n\"\n",
        "\n",
        "        print(final_report)\n",
        "        with open(f\"classification_report_{model_name}.txt\", \"a\") as f:\n",
        "            f.write(final_report + \"\\n\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    # Main model architecture - modified for binary classification\n",
        "    class BertClassifier(nn.Module, PyTorchModelHubMixin):\n",
        "        def __init__(self, version, num_labels=2, freeze_bert=False, num_Bottid_categories=30):\n",
        "            super(BertClassifier, self).__init__()\n",
        "\n",
        "            if version == \"bert-uncased\":\n",
        "                self.bert = AutoModel.from_pretrained('google-bert/bert-base-uncased')\n",
        "            elif version == \"businessBERT\":\n",
        "                self.bert = AutoModel.from_pretrained('pborchert/BusinessBERT')\n",
        "            elif version == \"bottleneckBERT\":\n",
        "                self.bert = AutoModel.from_pretrained('colaguo/bottleneckBERTsmall')\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid model version: {version}\")\n",
        "\n",
        "            self.version = version\n",
        "\n",
        "            self.linear_features = nn.Sequential(\n",
        "                nn.Linear(13, 16),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "            self.linear_Bottid = nn.Sequential(\n",
        "                nn.Linear(num_Bottid_categories, 8),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "            self.cls_head = nn.Sequential(\n",
        "                nn.Linear(self.bert.config.hidden_size, 128),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "            self.linear_combined_layer = nn.Sequential(\n",
        "                nn.Linear(128 + 16 + 8, 32),\n",
        "                nn.ReLU())\n",
        "\n",
        "            self.final_classifier = nn.Linear(32, num_labels)\n",
        "\n",
        "            self.pooling = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "            if freeze_bert:\n",
        "                for param in self.bert.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "        def forward(self, input_ids, attention_mask, features, Bottid_encoded):\n",
        "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            last_hidden_state = outputs.last_hidden_state\n",
        "            pooled_output = self.pooling(last_hidden_state.permute(0, 2, 1)).squeeze(-1)\n",
        "\n",
        "            bert_output = self.cls_head(pooled_output)\n",
        "            linear_features_output = self.linear_features(features)\n",
        "            Bottid_output = self.linear_Bottid(Bottid_encoded)\n",
        "\n",
        "            combined_output = torch.cat((bert_output, linear_features_output, Bottid_output), dim=1)\n",
        "            linear_layer_output = self.linear_combined_layer(combined_output)\n",
        "\n",
        "            logits = self.final_classifier(linear_layer_output)\n",
        "            return logits, linear_layer_output\n",
        "\n",
        "    def load_tokenizer(version):\n",
        "        if version == \"bert-uncased\":\n",
        "            return AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
        "        elif version == \"businessBERT\":\n",
        "            return AutoTokenizer.from_pretrained('pborchert/BusinessBERT')\n",
        "        elif version == \"bottleneckBERT\":\n",
        "            return AutoTokenizer.from_pretrained('colaguo/bottleneckBERTsmall')\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid model version: {version}\")\n",
        "\n",
        "    # Load original dataset\n",
        "    ogpath = \"nov25_combined.csv\"\n",
        "    train_df_original = pd.read_csv(\"/content/drive/MyDrive/BERTearningsdata/\" + \"train_\" + ogpath)\n",
        "    test_df_original = pd.read_csv(\"/content/drive/MyDrive/BERTearningsdata/\" + \"test_\" + ogpath)\n",
        "\n",
        "    def tokenize_function(examples, tokenizer):\n",
        "        return tokenizer(examples[\"paragraph\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "    class CustomDataset(Dataset):\n",
        "        def __init__(self, dataset, Bottid_categories=30):\n",
        "            self.dataset = dataset\n",
        "            self.Bottid_categories = Bottid_categories\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.dataset)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = self.dataset[idx]\n",
        "            input_ids = torch.tensor(item['input_ids'])\n",
        "            attention_mask = torch.tensor(item['attention_mask'])\n",
        "            label = torch.tensor(item['label'], dtype=torch.long)\n",
        "            features = torch.tensor([item['year'], item['word_count'], item['scarcity'],\n",
        "                                    item['nonuniform_progress'], item['performance_constraints'],\n",
        "                                    item['user_heterogeneity'], item['cognitive'], item['external'],\n",
        "                                    item['internal'], item['coordination'], item['transactional'],\n",
        "                                    item['technical'], item['demand']], dtype=torch.float)\n",
        "\n",
        "            Bottid_encoded = torch.tensor([item[f\"Bottid_{i}\"] for i in range(self.Bottid_categories)], dtype=torch.float)\n",
        "\n",
        "            return input_ids, attention_mask, features, Bottid_encoded, label\n",
        "\n",
        "    class FocalLoss(nn.Module):\n",
        "        def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
        "            super(FocalLoss, self).__init__()\n",
        "            self.alpha = alpha\n",
        "            self.gamma = gamma\n",
        "            self.reduction = reduction\n",
        "\n",
        "        def forward(self, inputs, targets):\n",
        "            \"\"\"\n",
        "            Focal Loss for binary or multi-class classification\n",
        "\n",
        "            Args:\n",
        "                inputs: logits from model (batch_size, num_classes)\n",
        "                targets: ground truth labels (batch_size)\n",
        "            \"\"\"\n",
        "            ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "            pt = torch.exp(-ce_loss)\n",
        "            focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "            if self.reduction == 'mean':\n",
        "                return focal_loss.mean()\n",
        "            elif self.reduction == 'sum':\n",
        "                return focal_loss.sum()\n",
        "            else:\n",
        "                return focal_loss\n",
        "\n",
        "    def get_exponential_warmup_schedule(optimizer, warmup_steps, initial_lr, target_lr, num_epochs, total_steps):\n",
        "        def warmup_lr_lambda(current_step):\n",
        "            if current_step < warmup_steps:\n",
        "                return float(current_step) / float(max(1, warmup_steps))\n",
        "            return 1.0\n",
        "\n",
        "        warmup_scheduler = LambdaLR(optimizer, lr_lambda=warmup_lr_lambda)\n",
        "        decay_rate = (target_lr / initial_lr)**(1 / (total_steps - warmup_steps))\n",
        "        decay_scheduler = ExponentialLR(optimizer, gamma=decay_rate)\n",
        "\n",
        "        return warmup_scheduler, decay_scheduler\n",
        "\n",
        "    def train_and_evaluate(model, train_dataloader, val_dataloader, optimizer, warmup_scheduler, decay_scheduler,\n",
        "                          epochs, loss_fn, focal_loss_fn, focal_weight, patience, num_classes,\n",
        "                          version, test_sets, model_name):\n",
        "        model.to(device)\n",
        "        best_f1 = 0.0\n",
        "        patience_counter = 0\n",
        "        current_step = 0\n",
        "        best_epoch = 0\n",
        "        output_dir = f\"model_output_{model_name}\"\n",
        "        best_model_state = None\n",
        "\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            total_ce_loss = 0\n",
        "            total_focal_loss = 0\n",
        "\n",
        "            for batch in train_dataloader:\n",
        "                input_ids, attention_mask, features, Bottid_encoded, labels = [t.to(device) for t in batch]\n",
        "                model.zero_grad()\n",
        "\n",
        "                logits, embeddings = model(input_ids, attention_mask, features, Bottid_encoded)\n",
        "\n",
        "                # Cross-entropy loss\n",
        "                ce_loss = loss_fn(logits, labels)\n",
        "\n",
        "                # Focal loss\n",
        "                focal_loss = focal_loss_fn(logits, labels)\n",
        "\n",
        "                # Combined loss\n",
        "                loss = ce_loss + focal_weight * focal_loss\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                if current_step < warmup_steps:\n",
        "                    warmup_scheduler.step()\n",
        "                decay_scheduler.step()\n",
        "\n",
        "                current_step += 1\n",
        "                total_loss += loss.item()\n",
        "                total_ce_loss += ce_loss.item()\n",
        "                total_focal_loss += focal_loss.item()\n",
        "\n",
        "            avg_train_loss = total_loss / len(train_dataloader)\n",
        "            avg_ce_loss = total_ce_loss / len(train_dataloader)\n",
        "            avg_focal_loss = total_focal_loss / len(train_dataloader)\n",
        "\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for batch in val_dataloader:\n",
        "                    input_ids, attention_mask, features, Bottid_encoded, labels = [t.to(device) for t in batch]\n",
        "                    logits, _ = model(input_ids, attention_mask, features, Bottid_encoded)\n",
        "                    val_loss += loss_fn(logits, labels).item()\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_dataloader)\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f} (CE: {avg_ce_loss:.4f}, Focal: {avg_focal_loss:.4f}), Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "            f1_score, _, _ = generate_classification_report(model, val_dataloader, num_classes, epoch=epoch+1, version=version, split_name=\"Val\", model_name=model_name)\n",
        "\n",
        "            if f1_score > best_f1:\n",
        "                best_f1 = f1_score\n",
        "                best_epoch = epoch + 1\n",
        "                patience_counter = 0\n",
        "                best_model_state = model.state_dict()\n",
        "                print(f\"New best F1 score: {best_f1:.4f} at epoch {epoch+1}.\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "\n",
        "        if best_model_state is not None:\n",
        "            model.load_state_dict(best_model_state)\n",
        "            model_filename = f\"{output_dir}/model_version_{version}.pth\"\n",
        "            torch.save(model.state_dict(), model_filename)\n",
        "            print(f\"Best model (version {version}) saved to {model_filename} with F1 {best_f1:.4f}\")\n",
        "\n",
        "            if test_sets is not None:\n",
        "                print(\"Evaluating on multiple test sets...\")\n",
        "                evaluate_on_multiple_test_sets(model, test_sets, num_classes=num_classes, version=version, model_name=model_name)\n",
        "                print(\"Evaluation on multiple test sets complete.\")\n",
        "\n",
        "        print(f\"Training completed. Best F1 score: {best_f1:.4f} achieved at epoch {best_epoch}.\")\n",
        "        return best_f1, model\n",
        "\n",
        "    def prepare_dataset(train_df, test_df, binary_model):\n",
        "        \"\"\"Prepare dataset for specific binary model\"\"\"\n",
        "        train_df = train_df.copy()\n",
        "        test_df = test_df.copy()\n",
        "\n",
        "        if binary_model == \"model1\":\n",
        "            # Model 1: Binary classification - label 0 vs label 1/2\n",
        "            train_df['label'] = train_df['label'].apply(lambda x: 0 if x == 0 else 1)\n",
        "            test_df['label'] = test_df['label'].apply(lambda x: 0 if x == 0 else 1)\n",
        "\n",
        "        elif binary_model == \"model2\":\n",
        "            # Model 2: Binary classification - label 1 vs label 2\n",
        "            train_df = train_df[train_df['label'].isin([1, 2])].copy()\n",
        "            test_df = test_df[test_df['label'].isin([1, 2])].copy()\n",
        "            train_df['label'] = train_df['label'].apply(lambda x: 0 if x == 1 else 1)\n",
        "            test_df['label'] = test_df['label'].apply(lambda x: 0 if x == 1 else 1)\n",
        "\n",
        "        # One-hot encode Bottid with fixed categories 1-30\n",
        "        encoder = OneHotEncoder(categories=[list(range(1, 31))], handle_unknown='ignore')\n",
        "        encoder.fit(train_df[['Bottid']])\n",
        "\n",
        "        train_encoded = encoder.transform(train_df[['Bottid']]).toarray()\n",
        "        test_encoded = encoder.transform(test_df[['Bottid']]).toarray()\n",
        "\n",
        "        # Always create 30 Bottid columns\n",
        "        feature_names = [f\"Bottid_{i}\" for i in range(30)]\n",
        "        train_encoded_df = pd.DataFrame(train_encoded, columns=feature_names)\n",
        "        test_encoded_df = pd.DataFrame(test_encoded, columns=feature_names)\n",
        "\n",
        "        train_df = pd.concat([train_df.reset_index(drop=True), train_encoded_df], axis=1)\n",
        "        test_df = pd.concat([test_df.reset_index(drop=True), test_encoded_df], axis=1)\n",
        "\n",
        "        train_df = train_df.drop('Bottid', axis=1)\n",
        "        test_df = test_df.drop('Bottid', axis=1)\n",
        "\n",
        "        return train_df, test_df, 30  # Always return 30 categories\n",
        "\n",
        "    def truncate_dataset(dataset):\n",
        "        k = round(len(dataset)*0.99)\n",
        "        random_indices = random.sample(range(len(dataset)), k)\n",
        "        return dataset.select(random_indices)\n",
        "\n",
        "    # Dictionary to store trained models\n",
        "    trained_models = {}\n",
        "\n",
        "    # Train both models\n",
        "    for binary_model in [\"model1\", \"model2\"]:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        if binary_model == \"model1\":\n",
        "            print(\"TRAINING MODEL 1: Label 0 vs Label 1/2\")\n",
        "        else:\n",
        "            print(\"TRAINING MODEL 2: Label 1 vs Label 2\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "        # Prepare dataset\n",
        "        train_df, test_df, num_Bottid_categories = prepare_dataset(train_df_original, test_df_original, binary_model)\n",
        "\n",
        "        # Convert to HuggingFace datasets\n",
        "        from datasets import Dataset as HFDataset\n",
        "        dataset = {\n",
        "            'train': HFDataset.from_pandas(train_df),\n",
        "            'test': HFDataset.from_pandas(test_df)\n",
        "        }\n",
        "        dataset = {k: truncate_dataset(v) for k, v in dataset.items()}\n",
        "\n",
        "        for version in version_list:\n",
        "            print(f\"\\n----- Running {binary_model} with {version} -----\")\n",
        "\n",
        "            tokenizer = load_tokenizer(version)\n",
        "            tokenized_datasets = {split: data.map(lambda examples: tokenize_function(examples, tokenizer), batched=True)\n",
        "                                 for split, data in dataset.items()}\n",
        "            train_dataset = tokenized_datasets[\"train\"]\n",
        "            test_dataset = tokenized_datasets[\"test\"]\n",
        "\n",
        "            train_data = CustomDataset(train_dataset, Bottid_categories=num_Bottid_categories)\n",
        "            test_data = CustomDataset(test_dataset, Bottid_categories=num_Bottid_categories)\n",
        "\n",
        "            test_sets = create_test_sets(test_data, num_classes=2)\n",
        "\n",
        "            train_labels = [item['label'] for item in train_dataset]\n",
        "            label_counts = Counter(train_labels)\n",
        "            print(\"Binary label distribution:\", label_counts)\n",
        "\n",
        "            train_data_loader = DataLoader(train_data, batch_size=default_batch_size, shuffle=True)\n",
        "\n",
        "            # Binary class weights\n",
        "            if binary_model == \"model1\":\n",
        "                normalized_weights = torch.tensor([1.0, 1.3])\n",
        "            else:\n",
        "                normalized_weights = torch.tensor([1.0, 1.3])\n",
        "\n",
        "            loss_fn = nn.CrossEntropyLoss(weight=normalized_weights.to(device), label_smoothing=0.1)\n",
        "            focal_loss_fn = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)\n",
        "\n",
        "            model = BertClassifier(version, num_labels=2, num_Bottid_categories=num_Bottid_categories).to(device)\n",
        "\n",
        "            train_dataloader = train_data_loader\n",
        "            val_dataloader = DataLoader(test_data, batch_size=default_batch_size)\n",
        "\n",
        "            optimizer = torch.optim.AdamW(model.parameters(), lr=default_lr, eps=default_eps)\n",
        "\n",
        "            total_steps = len(train_dataloader) * num_epochs\n",
        "            warmup_steps = int(warmup_proportion * total_steps)\n",
        "\n",
        "            warmup_scheduler, decay_scheduler = get_exponential_warmup_schedule(\n",
        "                optimizer, warmup_steps, default_lr, target_lr, num_epochs, total_steps\n",
        "            )\n",
        "\n",
        "            best_f1, trained_model = train_and_evaluate(\n",
        "                model, train_dataloader, val_dataloader, optimizer, warmup_scheduler,\n",
        "                decay_scheduler, epochs=num_epochs, loss_fn=loss_fn, focal_loss_fn=focal_loss_fn,\n",
        "                focal_weight=focal_weight, num_classes=2, patience=patience, version=version, test_sets=test_sets,\n",
        "                model_name=binary_model\n",
        "            )\n",
        "\n",
        "            # Store the trained model and its dataset info\n",
        "            trained_models[binary_model] = {\n",
        "                'model': trained_model,\n",
        "                'version': version,\n",
        "                'num_Bottid_categories': num_Bottid_categories,\n",
        "                'tokenizer': tokenizer\n",
        "            }\n",
        "\n",
        "    # HIERARCHICAL CLASSIFICATION ON ORIGINAL TEST SET\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"HIERARCHICAL CLASSIFICATION: Combining Both Models on Original Test Set\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Prepare original test set (with original 3-class labels)\n",
        "    test_df_hier = test_df_original.copy()\n",
        "\n",
        "    # Store original labels\n",
        "    original_labels = test_df_hier['label'].values\n",
        "\n",
        "    # One-hot encode for hierarchical prediction with fixed categories\n",
        "    encoder = OneHotEncoder(categories=[list(range(1, 31))], handle_unknown='ignore')\n",
        "    encoder.fit(test_df_hier[['Bottid']])\n",
        "    test_encoded = encoder.transform(test_df_hier[['Bottid']]).toarray()\n",
        "\n",
        "    # Always create 30 Bottid columns\n",
        "    feature_names = [f\"Bottid_{i}\" for i in range(30)]\n",
        "    test_encoded_df = pd.DataFrame(test_encoded, columns=feature_names)\n",
        "    test_df_hier = pd.concat([test_df_hier.reset_index(drop=True), test_encoded_df], axis=1)\n",
        "    test_df_hier = test_df_hier.drop('Bottid', axis=1)\n",
        "\n",
        "    # Create dataset\n",
        "    from datasets import Dataset as HFDataset\n",
        "    test_dataset_hier = HFDataset.from_pandas(test_df_hier)\n",
        "\n",
        "    # Get model 1 info\n",
        "    model1_info = trained_models['model1']\n",
        "    tokenizer = model1_info['tokenizer']\n",
        "\n",
        "    # Tokenize\n",
        "    test_dataset_hier = test_dataset_hier.map(lambda examples: tokenize_function(examples, tokenizer), batched=True)\n",
        "    test_data_hier = CustomDataset(test_dataset_hier, Bottid_categories=30)\n",
        "\n",
        "    # Hierarchical prediction\n",
        "    model1 = trained_models['model1']['model']\n",
        "    model2 = trained_models['model2']['model']\n",
        "\n",
        "    model1.eval()\n",
        "    model2.eval()\n",
        "\n",
        "    hierarchical_predictions = []\n",
        "\n",
        "    print(\"Making hierarchical predictions...\")\n",
        "    with torch.no_grad():\n",
        "        for idx in range(len(test_data_hier)):\n",
        "            input_ids, attention_mask, features, Bottid_encoded, _ = test_data_hier[idx]\n",
        "\n",
        "            # Add batch dimension\n",
        "            input_ids = input_ids.unsqueeze(0).to(device)\n",
        "            attention_mask = attention_mask.unsqueeze(0).to(device)\n",
        "            features = features.unsqueeze(0).to(device)\n",
        "            Bottid_encoded = Bottid_encoded.unsqueeze(0).to(device)\n",
        "\n",
        "            # First model: 0 vs 1/2\n",
        "            logits1, _ = model1(input_ids, attention_mask, features, Bottid_encoded)\n",
        "            pred1 = torch.argmax(logits1, dim=1).item()\n",
        "\n",
        "            if pred1 == 0:\n",
        "                # Predicted class 0\n",
        "                final_pred = 0\n",
        "            else:\n",
        "                # Predicted 1 or 2, use model2 to distinguish\n",
        "                logits2, _ = model2(input_ids, attention_mask, features, Bottid_encoded)\n",
        "                pred2 = torch.argmax(logits2, dim=1).item()\n",
        "                # pred2: 0 means original label 1, 1 means original label 2\n",
        "                final_pred = 1 if pred2 == 0 else 2\n",
        "\n",
        "            hierarchical_predictions.append(final_pred)\n",
        "\n",
        "    hierarchical_predictions = np.array(hierarchical_predictions)\n",
        "\n",
        "    # Generate comprehensive report\n",
        "    report = classification_report(original_labels, hierarchical_predictions,\n",
        "                                   target_names=['0', '1', '2'], digits=4)\n",
        "\n",
        "    cm = confusion_matrix(original_labels, hierarchical_predictions, labels=[0, 1, 2])\n",
        "    cm_report = \"\\nConfusion Matrix:\\n\"\n",
        "    cm_report += \"            Predicted\\n\"\n",
        "    cm_report += \"           \" + \"    \".join(map(str, [0, 1, 2])) + \"\\n\"\n",
        "    cm_report += \"Actual\\n\"\n",
        "    for i, row in enumerate(cm):\n",
        "        cm_report += f\"      {i}   \" + \"    \".join(map(str, row)) + \"\\n\"\n",
        "\n",
        "    final_report = f\"\"\"\n",
        "{'='*80}\n",
        "HIERARCHICAL CLASSIFICATION REPORT (3-Class on Original Test Set)\n",
        "Model 1 (0 vs 1/2) -> Model 2 (1 vs 2)\n",
        "{'='*80}\n",
        "\n",
        "{report}\n",
        "\n",
        "{cm_report}\n",
        "\"\"\"\n",
        "\n",
        "    print(final_report)\n",
        "    with open(\"classification_report_hierarchical.txt\", \"w\") as f:\n",
        "        f.write(final_report + \"\\n\")\n",
        "\n",
        "    print(\"\\nHierarchical classification complete!\")\n",
        "    print(\"Results saved to: classification_report_hierarchical.txt\")"
      ],
      "metadata": {
        "id": "IwCGCkTINGyz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}