{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b1756370a57c41b78c7736f1c6921113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bd710613d5f458884d14e51ad5916b9",
              "IPY_MODEL_d00ddcb6f076417bb0460e18ac4cc1b2",
              "IPY_MODEL_6c0919fc99bf4d728b9d8283141f152c"
            ],
            "layout": "IPY_MODEL_0ebee8f857b14a84a386da6ebe8fc213"
          }
        },
        "1bd710613d5f458884d14e51ad5916b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c352bce3ee974b0583805bdb8258dae3",
            "placeholder": "​",
            "style": "IPY_MODEL_8bab3050021f400591a2660edfc2d037",
            "value": "Map: 100%"
          }
        },
        "d00ddcb6f076417bb0460e18ac4cc1b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7849f8b69dc340a7920cb2ee21ec6b1b",
            "max": 5582,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e5b51f6f634442eb39611ad9102ea8c",
            "value": 5582
          }
        },
        "6c0919fc99bf4d728b9d8283141f152c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d59db225fb784e9993b02f38a9f5c622",
            "placeholder": "​",
            "style": "IPY_MODEL_0e8365c045514578a3fb39ea56b65c8c",
            "value": " 5582/5582 [00:03&lt;00:00, 1550.85 examples/s]"
          }
        },
        "0ebee8f857b14a84a386da6ebe8fc213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c352bce3ee974b0583805bdb8258dae3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bab3050021f400591a2660edfc2d037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7849f8b69dc340a7920cb2ee21ec6b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e5b51f6f634442eb39611ad9102ea8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d59db225fb784e9993b02f38a9f5c622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e8365c045514578a3fb39ea56b65c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07ff9d6debcb496ca9cdd223fd421f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e62fcf8ebf2462997b548051644ade1",
              "IPY_MODEL_3c43549e57b842d4b8651012a19dd712",
              "IPY_MODEL_3d9a65f32efb4e30ac4964afb9c055f3"
            ],
            "layout": "IPY_MODEL_6fef30e211ab4aa7b688fbbff6f83a9d"
          }
        },
        "8e62fcf8ebf2462997b548051644ade1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_240eb6fd556848ebb4be9017884ec482",
            "placeholder": "​",
            "style": "IPY_MODEL_b5630fd3296d4840ae2084485a4f966b",
            "value": "Map: 100%"
          }
        },
        "3c43549e57b842d4b8651012a19dd712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c281cba497ed47fc9906b599cc68b450",
            "max": 2393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e157e12632b4a6a881485fa165fb959",
            "value": 2393
          }
        },
        "3d9a65f32efb4e30ac4964afb9c055f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5b060d2f45b4bca8443d3269afd20ce",
            "placeholder": "​",
            "style": "IPY_MODEL_59896ef162a34005a8c18cd7fef245f5",
            "value": " 2393/2393 [00:01&lt;00:00, 1790.72 examples/s]"
          }
        },
        "6fef30e211ab4aa7b688fbbff6f83a9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "240eb6fd556848ebb4be9017884ec482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5630fd3296d4840ae2084485a4f966b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c281cba497ed47fc9906b599cc68b450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e157e12632b4a6a881485fa165fb959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5b060d2f45b4bca8443d3269afd20ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59896ef162a34005a8c18cd7fef245f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/col-a-guo/guo_chen_jang_ms_project/blob/main/BERTearnings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMT74j2CWx4V",
        "outputId": "46bbae83-cb5f-440c-befb-11b15485d233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (0.35.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.12/dist-packages (0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (from imblearn) (0.14.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers datasets torchmetrics scikit-learn numpy huggingface-hub pandas imblearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "qfI3GWR8L08v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453cb809-ae5a-4fce-c62a-a665a7dae840"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QRwF2e0Jfmh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "FILE_PATH = '/content/drive/MyDrive/BERTearningsdata/'\n",
        "print(os.listdir('/content/drive/MyDrive/BERTearningsdata/'))"
      ],
      "metadata": {
        "id": "sSCWyzOyMlYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac617d1-3406-478e-e118-19cd35a1260b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train_sept22_combined.csv', 'test_sept22_combined.csv', 'sept22_combined.csv', 'sept1_combined.csv', 'test_sept1_combined.csv', 'train_sept1_combined.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from transformers import get_scheduler\n",
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "#from imblearn.under_sampling import RandomUnderSampler\n",
        "import torchmetrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import random\n",
        "import numpy as np\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from torch.optim.lr_scheduler import LambdaLR, ExponentialLR\n",
        "import os\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    seed_value = 1\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "    version_list = [\"bottleneckBERT\"]\n",
        "    # Default hyperparameters\n",
        "    default_lr = 2e-5 #initial learning rate\n",
        "    target_lr = 9e-6 #Target after 10 epochs\n",
        "    default_eps = 6.748313060587885e-08\n",
        "    default_batch_size = 32\n",
        "    num_epochs = 200\n",
        "    patience = 3\n",
        "    warmup_proportion = 0.2\n",
        "\n",
        "    # function to generate classification report for multi-class\n",
        "    def generate_classification_report(model, dataloader, num_classes, epoch=None, version=None, split_name=\"Test\"):\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        with torch.no_grad(): #run once, don't update gradients during reporting\n",
        "            for batch in dataloader:\n",
        "                input_ids, attention_mask, features, Bottid_encoded, labels = [t.to(device) for t in batch] #unpack Bottid because one hot encoded\n",
        "                logits = model(input_ids, attention_mask, features, Bottid_encoded) # pass Bottid to model\n",
        "                preds = torch.argmax(logits, dim=1)  # multi-class prediction\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Convert to numpy arrays for sklearn functions\n",
        "        all_preds = np.array(all_preds)\n",
        "        all_labels = np.array(all_labels)\n",
        "\n",
        "        report = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(num_classes)], digits=4)\n",
        "\n",
        "        cm = confusion_matrix(all_labels, all_preds, labels=list(range(num_classes)))\n",
        "        cm_report = \"\\nConfusion Matrix:\\n\"\n",
        "        cm_report += \"            Predicted\\n\"\n",
        "        cm_report += \"           \" + \"    \".join(map(str, range(num_classes))) + \"\\n\"\n",
        "        cm_report += \"Actual\\n\"\n",
        "        for i, row in enumerate(cm):\n",
        "            cm_report += f\"      {i}   \" + \"    \".join(map(str, row)) + \"\\n\"\n",
        "\n",
        "\n",
        "        final_report = f\"\"\"\n",
        "    Classification Report ({split_name}, Version: {version}, Epoch {epoch if epoch is not None else 'Final'}):\\n\n",
        "    {report}\\n\n",
        "    {cm_report}\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "        print(final_report)\n",
        "        with open(\"classification_report.txt\", \"a\") as f:\n",
        "            f.write(final_report + \"\\n\")\n",
        "\n",
        "        f1 = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(num_classes)], output_dict=True, zero_division=0)['weighted avg']['f1-score'] # Added zero_division\n",
        "\n",
        "        return f1, all_preds, all_labels\n",
        "\n",
        "    def create_test_sets(test_dataset, num_sets=10, subset_size=0.9):\n",
        "        \"\"\"\n",
        "        Splits the test set into `num_sets` subsets, each containing `subset_size` proportion\n",
        "        of the data for each label, for Monte Carlo cross validation (MCCV)\n",
        "\n",
        "        Args:\n",
        "            test_dataset: your test dataset\n",
        "            num_sets: int, the number of test subsets to create.\n",
        "            subset_size: 0<float<1, proportion of subset (e.g., 0.2 for 20%).\n",
        "\n",
        "        Returns:\n",
        "            test_sets: subsets of your test dataset\n",
        "        \"\"\"\n",
        "\n",
        "        # Get indices of samples for each label\n",
        "        label_0_indices = [i for i, item in enumerate(test_dataset) if item[-1] == 0] #item[-1] is label\n",
        "        label_1_indices = [i for i, item in enumerate(test_dataset) if item[-1] == 1]\n",
        "        label_2_indices = [i for i, item in enumerate(test_dataset) if item[-1] == 2]  # Added for label 2\n",
        "\n",
        "        # Calculate the number of samples to select for each label in each subset\n",
        "        num_label_0_samples = int(len(label_0_indices) * subset_size)\n",
        "        num_label_1_samples = int(len(label_1_indices) * subset_size)\n",
        "        num_label_2_samples = int(len(label_2_indices) * subset_size)  # Added for label 2\n",
        "\n",
        "        test_sets = []\n",
        "        for _ in range(num_sets):\n",
        "            # Randomly select indices for each label\n",
        "            subset_label_0_indices = random.sample(label_0_indices, num_label_0_samples)\n",
        "            subset_label_1_indices = random.sample(label_1_indices, num_label_1_samples)\n",
        "            subset_label_2_indices = random.sample(label_2_indices, num_label_2_samples)  # Added for label 2\n",
        "\n",
        "            # Combine the indices\n",
        "            subset_indices = subset_label_0_indices + subset_label_1_indices + subset_label_2_indices  # Added label_2\n",
        "            random.shuffle(subset_indices)  # Shuffle the combined indices\n",
        "\n",
        "            # Create a Subset from the selected indices\n",
        "            subset = Subset(test_dataset, subset_indices)\n",
        "            test_sets.append(subset)\n",
        "\n",
        "        return test_sets\n",
        "\n",
        "    def evaluate_on_multiple_test_sets(model, test_sets, num_classes=3, version=None):\n",
        "        \"\"\"\n",
        "        Evaluates the model on multiple test sets and calculates the average performance and standard deviations.\n",
        "\n",
        "        Args:\n",
        "            model: The trained PyTorch model.\n",
        "            test_sets: test subsets from create_testsets\n",
        "            num_classes: int, for classification\n",
        "            version: str, for recording versions\n",
        "\n",
        "        Returns:\n",
        "            results: dict containing the average classification report metrics and standard deviations.\n",
        "        \"\"\"\n",
        "\n",
        "        all_reports = []\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        #take test sets and get results\n",
        "        for i, test_set in enumerate(test_sets):\n",
        "            dataloader = DataLoader(test_set, batch_size=default_batch_size)\n",
        "            f1, preds, labels = generate_classification_report(model, dataloader, num_classes, version=version, split_name=f\"Test Set {i+1}\")\n",
        "            all_reports.append(classification_report(labels, preds, target_names=[str(i) for i in range(num_classes)], output_dict=True, zero_division=0))\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "        #create metrics across test sets: mean, stdev across precision/recall/f1/support\n",
        "        metrics = {}\n",
        "        for class_idx in range(num_classes):\n",
        "            class_str = str(class_idx)\n",
        "            metrics[f'precision_{class_str}'] = [report[class_str]['precision'] for report in all_reports]\n",
        "            metrics[f'recall_{class_str}'] = [report[class_str]['recall'] for report in all_reports]\n",
        "            metrics[f'f1-score_{class_str}'] = [report[class_str]['f1-score'] for report in all_reports]\n",
        "            metrics[f'support_{class_str}'] = [report[class_str]['support'] for report in all_reports]\n",
        "\n",
        "        metrics['macro_avg_precision'] = [report['macro avg']['precision'] for report in all_reports]\n",
        "        metrics['macro_avg_recall'] = [report['macro avg']['recall'] for report in all_reports]\n",
        "        metrics['macro_avg_f1-score'] = [report['macro avg']['f1-score'] for report in all_reports]\n",
        "        metrics['macro_avg_support'] = [report['macro avg']['support'] for report in all_reports]\n",
        "\n",
        "        metrics['weighted_avg_precision'] = [report['weighted avg']['precision'] for report in all_reports]\n",
        "        metrics['weighted_avg_recall'] = [report['weighted avg']['recall'] for report in all_reports]\n",
        "        metrics['weighted_avg_f1-score'] = [report['weighted avg']['f1-score'] for report in all_reports]\n",
        "        metrics['weighted_avg_support'] = [report['weighted avg']['support'] for report in all_reports]\n",
        "\n",
        "        results = {}\n",
        "        for metric_name, values in metrics.items():\n",
        "            results[metric_name + \"_avg\"] = np.mean(values)\n",
        "            results[metric_name + \"_std\"] = np.std(values)\n",
        "\n",
        "        #Print final report\n",
        "        final_report = \"Averaged performance across all test sets:\\n\"\n",
        "        for metric_name, value in results.items():\n",
        "            if \"_avg\" in metric_name:\n",
        "                std_name = metric_name.replace(\"_avg\", \"_std\")\n",
        "            if std_name in results: # Check to make sure that we don't cause a key error\n",
        "                final_report += f\"{metric_name}: {value:.4f} +/- {results[std_name]:.4f}\\n\"\n",
        "\n",
        "        print(final_report)\n",
        "        with open(\"classification_report.txt\", \"a\") as f:\n",
        "            f.write(final_report + \"\\n\")\n",
        "\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    #main model architecture\n",
        "    class BertClassifier(nn.Module, PyTorchModelHubMixin):\n",
        "        def __init__(self, version, num_labels=3, freeze_bert=False, num_Bottid_categories=29):\n",
        "            super(BertClassifier, self).__init__()\n",
        "\n",
        "            if version == \"bert-uncased\":\n",
        "                self.bert = AutoModel.from_pretrained('google-bert/bert-base-uncased')\n",
        "            elif version == \"businessBERT\":\n",
        "                self.bert = AutoModel.from_pretrained('pborchert/BusinessBERT')\n",
        "            elif version == \"bottleneckBERT\":\n",
        "                self.bert = AutoModel.from_pretrained('colaguo/bottleneckBERTsmall')\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid model version: {version}\")\n",
        "\n",
        "            self.version = version\n",
        "\n",
        "            #First linear layer, key features sent to 16 params\n",
        "            self.linear_features = nn.Sequential(\n",
        "                nn.Linear(13, 32),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "            #First linear layer, Bottids sent to 4 params (less than key features, emphasized/explored less than others)\n",
        "            self.linear_Bottid = nn.Sequential(\n",
        "                nn.Linear(num_Bottid_categories, 8),  # Linear layer for Bottid encoding\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "            #First linear layer, BERT output sent to 256 params, biggest part\n",
        "            self.cls_head = nn.Sequential(\n",
        "                nn.Linear(self.bert.config.hidden_size, 256),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "            #Second linear layer, concatenate first layer -> 32\n",
        "            self.linear_combined_layer = nn.Sequential(\n",
        "                nn.Linear(256 + 32 + 8, 32),\n",
        "                nn.ReLU())\n",
        "\n",
        "            self.final_classifier = nn.Linear(32, num_labels)\n",
        "\n",
        "            self.pooling = nn.AdaptiveAvgPool1d(1) # Global avg pool\n",
        "\n",
        "\n",
        "            if freeze_bert:\n",
        "                for param in self.bert.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "        #TODO: Add bottleneck features here?\n",
        "                    #feedforward, sequential, 11 -> 8 -> num_labels, concatenate with pooled\n",
        "                    #try simple concatenate, then try lower weight/layer down to 128, 64, etc\n",
        "                    #try business, our bert, hybridization, ??\n",
        "                    #focus on / find tokens with captum?\n",
        "                    #check library for past reports maybe\n",
        "\n",
        "        def forward(self, input_ids, attention_mask, features, Bottid_encoded): # Take Bottid as input\n",
        "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            # Global abg pool\n",
        "            last_hidden_state = outputs.last_hidden_state\n",
        "            pooled_output = self.pooling(last_hidden_state.permute(0, 2, 1)).squeeze(-1)\n",
        "\n",
        "            bert_output = self.cls_head(pooled_output)\n",
        "\n",
        "            linear_features_output = self.linear_features(features)\n",
        "            Bottid_output = self.linear_Bottid(Bottid_encoded) # Pass Bottid through linear layer\n",
        "\n",
        "            combined_output = torch.cat((bert_output, linear_features_output, Bottid_output), dim=1) #Concatenate 3 inputs\n",
        "\n",
        "            linear_layer_output = self.linear_combined_layer(combined_output)\n",
        "\n",
        "            logits = self.final_classifier(linear_layer_output)\n",
        "            return logits\n",
        "\n",
        "\n",
        "\n",
        "    # Function to load the correct tokenizer\n",
        "    def load_tokenizer(version):\n",
        "        if version == \"bert-uncased\":\n",
        "            return AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
        "        elif version == \"businessBERT\":\n",
        "            return AutoTokenizer.from_pretrained('pborchert/BusinessBERT')\n",
        "        elif version == \"bottleneckBERT\":\n",
        "            return AutoTokenizer.from_pretrained('colaguo/bottleneckBERTsmall')\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid model version: {version}\")\n",
        "\n",
        "    # Load dataset and preprocess# Load dataset and preprocess\n",
        "    ogpath = \"sept22_combined.csv\"\n",
        "    dataset = load_dataset('csv', data_files={'train': \"/content/drive/MyDrive/BERTearningsdata/\" + \"train_\" + ogpath, 'test': \"/content/drive/MyDrive/BERTearningsdata/\" +\"test_\" + ogpath})\n",
        "\n",
        "    train_df = pd.read_csv(\"/content/drive/MyDrive/BERTearningsdata/\" + \"train_\" + ogpath)\n",
        "    test_df = pd.read_csv(\"/content/drive/MyDrive/BERTearningsdata/\" + \"test_\" + ogpath)\n",
        "    test_df.loc[test_df['label'] > 2, 'label'] = 2  # Or remove rows, or re-assign as needed\n",
        "\n",
        "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "    encoder.fit(train_df[['Bottid']])\n",
        "    train_encoded = encoder.transform(train_df[['Bottid']]).toarray()\n",
        "    test_encoded = encoder.transform(test_df[['Bottid']]).toarray()\n",
        "\n",
        "    # get_feature_names_out is deprecated, warning says to use get_feature_names instead\n",
        "    # but this throws an error locally and I don't want to deal with it\n",
        "    # using manual for Bottid\n",
        "    feature_names = [f\"Bottid_{i}\" for i in range(train_encoded.shape[1])]\n",
        "\n",
        "    # create a temporary dataframe to store encoded values, with feature names\n",
        "    train_encoded_df = pd.DataFrame(train_encoded, columns=feature_names)\n",
        "    test_encoded_df = pd.DataFrame(test_encoded, columns=feature_names)\n",
        "\n",
        "\n",
        "    train_df = pd.concat([train_df, train_encoded_df], axis=1)\n",
        "    test_df = pd.concat([test_df, test_encoded_df], axis=1)\n",
        "\n",
        "    # Remove the original Bottid column\n",
        "    train_df = train_df.drop('Bottid', axis=1)\n",
        "    test_df = test_df.drop('Bottid', axis=1)\n",
        "\n",
        "    #Convert the dataframes back to HuggingFace datasets\n",
        "    dataset['train'] = dataset['train'].from_pandas(train_df)\n",
        "    dataset['test'] = dataset['test'].from_pandas(test_df)\n",
        "\n",
        "    # Truncate dataset; useful to avoid resampling errors due to requesting more samples than exist\n",
        "    # also reducing to very small numbers for rapid prototyping/testing\n",
        "    def truncate_dataset(dataset):\n",
        "        k = round(len(dataset)*0.99)\n",
        "        random_indices = random.sample(range(len(dataset)), k)\n",
        "        return dataset.select(random_indices)\n",
        "\n",
        "    dataset = {k: truncate_dataset(v) for k, v in dataset.items()}\n",
        "\n",
        "    # No longer filtering out label 2.  Need to keep it now\n",
        "\n",
        "    #def filter_label_2(dataset):\n",
        "    #    filtered_dataset = dataset.filter(lambda example: example['label'] != 2)\n",
        "    #    return filtered_dataset\n",
        "\n",
        "    #dataset = {k: filter_label_2(v) for k, v in dataset.items()}\n",
        "\n",
        "    def tokenize_function(examples, tokenizer):\n",
        "        return tokenizer(examples[\"paragraph\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "    class CustomDataset(Dataset):\n",
        "        def __init__(self, dataset, Bottid_categories=29): #Added Bottid_categories, 29 should be the #. of Bottids; notably reduced from full list because of low/0 prevalence\n",
        "            self.dataset = dataset\n",
        "            self.Bottid_categories = Bottid_categories\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.dataset)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = self.dataset[idx]\n",
        "            input_ids = torch.tensor(item['input_ids'])\n",
        "            attention_mask = torch.tensor(item['attention_mask'])\n",
        "            label = torch.tensor(item['label'], dtype=torch.long)\n",
        "            features = torch.tensor([item['year'], item['word_count'], item['scarcity'], item['nonuniform_progress'], item['performance_constraints'], item['user_heterogeneity'], item['cognitive'], item['external'], item['internal'], item['coordination'], item['transactional'], item['technical'], item['demand']], dtype=torch.float)\n",
        "\n",
        "            # Extract the one-hot encoded Bottid features\n",
        "            Bottid_encoded = torch.tensor([item[f\"Bottid_{i}\"] for i in range(self.Bottid_categories)], dtype=torch.float)\n",
        "\n",
        "            return input_ids, attention_mask, features, Bottid_encoded, label # Returns Bottid encoding, label\n",
        "\n",
        "    def get_exponential_warmup_schedule(optimizer, warmup_steps, initial_lr, target_lr, num_epochs, total_steps):\n",
        "        \"\"\"\n",
        "        Combines a linear warmup with an exponential decay to reach a target learning rate\n",
        "        after a specified number of epochs.\n",
        "\n",
        "        Args:\n",
        "            optimizer: The optimizer.\n",
        "            warmup_steps: Number of steps for the warmup phase.\n",
        "            initial_lr: The initial learning rate.\n",
        "            target_lr: The target learning rate after num_epochs.\n",
        "            num_epochs: The number of epochs to reach the target_lr.\n",
        "            total_steps: Total number of training steps.\n",
        "\n",
        "        Returns:\n",
        "            A tuple of learning rate schedulers (warmup, exponential).\n",
        "        \"\"\"\n",
        "\n",
        "        def warmup_lr_lambda(current_step):\n",
        "            if current_step < warmup_steps:\n",
        "                return float(current_step) / float(max(1, warmup_steps))\n",
        "            return 1.0  # Keep LR at 1.0 after warmup\n",
        "\n",
        "        warmup_scheduler = LambdaLR(optimizer, lr_lambda=warmup_lr_lambda)\n",
        "\n",
        "        # Calculate decay rate to reach target_lr after num_epochs\n",
        "        decay_rate = (target_lr / initial_lr)**(1 / (total_steps - warmup_steps))\n",
        "        decay_scheduler = ExponentialLR(optimizer, gamma=decay_rate)\n",
        "\n",
        "        return warmup_scheduler, decay_scheduler\n",
        "\n",
        "    # Training function\n",
        "    def train_and_evaluate(model, train_dataloader, val_dataloader, optimizer, warmup_scheduler, decay_scheduler, epochs, loss_fn, patience=4, num_classes=3, version=None, test_sets=None):\n",
        "        model.to(device)\n",
        "        best_f1 = 0.0\n",
        "        patience_counter = 0\n",
        "        current_step = 0\n",
        "        best_epoch = 0  # Keep track of the epoch with the best F1\n",
        "        output_dir = \"model_output\"  # Define directory\n",
        "        best_model_state = None #To store the state dict of best model\n",
        "\n",
        "        # Create the output directory if it doesn't exist\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        #main training loop\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            for batch in train_dataloader:\n",
        "                input_ids, attention_mask, features, Bottid_encoded, labels = [t.to(device) for t in batch] #Unpack Bottid\n",
        "                model.zero_grad()\n",
        "                logits = model(input_ids, attention_mask, features, Bottid_encoded) #Pass Bottid to model\n",
        "                loss = loss_fn(logits, labels) #weighted CrossEntropyLoss\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                if current_step < warmup_steps:\n",
        "                    warmup_scheduler.step()\n",
        "                decay_scheduler.step()  # Always step the decay scheduler\n",
        "\n",
        "                current_step += 1\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "            # Validation\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for batch in val_dataloader:\n",
        "                    input_ids, attention_mask, features, Bottid_encoded, labels = [t.to(device) for t in batch] #Unpack Bottid\n",
        "                    logits = model(input_ids, attention_mask, features, Bottid_encoded) #Pass Bottid to model\n",
        "                    val_loss += loss_fn(logits, labels).item() #weighted CrossEntropyLoss\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_dataloader)\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "            # Generate and save the classification report every epoch\n",
        "            f1_score,_,_ = generate_classification_report(model, val_dataloader, num_classes, epoch=epoch+1, version=version, split_name=\"Val\")\n",
        "\n",
        "            # Early stopping based on F1 score\n",
        "            if f1_score > best_f1:\n",
        "                best_f1 = f1_score\n",
        "                best_epoch = epoch + 1 # Store the best epoch\n",
        "                patience_counter = 0\n",
        "                best_model_state = model.state_dict() # Save best model state\n",
        "                print(f\"New best F1 score: {best_f1:.4f} at epoch {epoch+1}.\") # Epoch logging\n",
        "\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "\n",
        "        # Load best model weights, then save\n",
        "        if best_model_state is not None:\n",
        "            model.load_state_dict(best_model_state)\n",
        "            model_filename = f\"model_output/model_version_{version}.pth\"  # Added version\n",
        "            torch.save(model.state_dict(), model_filename)  #Save the model's weights\n",
        "            print(f\"Best model (version {version}) saved to {model_filename} with F1 {best_f1:.4f}\")\n",
        "\n",
        "            # Evaluate and report on multiple test sets when a new best model is found\n",
        "            if test_sets is not None:\n",
        "                print(\"Evaluating on multiple test sets...\")\n",
        "                evaluate_on_multiple_test_sets(model, test_sets, num_classes=num_classes, version=version)\n",
        "                print(\"Evaluation on multiple test sets complete.\")\n",
        "\n",
        "\n",
        "        # tokenizer.push_to_hub(f\"colaguo/{version}_finetune_feb24\")\n",
        "        # # push to the hub removed for this version\n",
        "        # model.push_to_hub(f\"colaguo/{version}_finetune_feb24\")\n",
        "\n",
        "        print(f\"Training completed. Best F1 score: {best_f1:.4f} achieved at epoch {best_epoch}.\") #Log the best F1 after training.\n",
        "        return best_f1\n",
        "\n",
        "    # Main loop\n",
        "    for version in version_list:\n",
        "        print(f\"\\n----- Running with {version} -----\")\n",
        "\n",
        "        tokenizer = load_tokenizer(version)\n",
        "        tokenized_datasets = {split: data.map(lambda examples: tokenize_function(examples, tokenizer), batched=True) for split, data in dataset.items()}\n",
        "        train_dataset = tokenized_datasets[\"train\"]\n",
        "        test_dataset = tokenized_datasets[\"test\"]\n",
        "\n",
        "        num_Bottid_categories = train_encoded.shape[1] #Determine the number of Bottid categories\n",
        "        train_data = CustomDataset(train_dataset, Bottid_categories=num_Bottid_categories) # pass to CustomDataset\n",
        "        test_data = CustomDataset(test_dataset, Bottid_categories=num_Bottid_categories) # pass to CustomDataset\n",
        "\n",
        "        #Create test sets:\n",
        "        test_sets = create_test_sets(test_data)\n",
        "\n",
        "        # Undersampling to balance labels\n",
        "        train_labels = [item['label'] for item in train_dataset]\n",
        "        label_counts = Counter(train_labels)\n",
        "        print(\"Original label distribution:\", label_counts)\n",
        "\n",
        "        # Determine the minimum count of a class\n",
        "        min_count = min(label_counts.values())\n",
        "\n",
        "        # REMOVED: Undersampling replaced by loss weights\n",
        "        # sampler = RandomUnderSampler(sampling_strategy={0:int(round(min_count*1.4)), 1:min_count}) #3200:400\n",
        "        # train_indices = list(range(len(train_labels)))\n",
        "        # resampled_indices, resampled_labels = sampler.fit_resample(np.array(train_indices).reshape(-1, 1), np.array(train_indices))\n",
        "        # resampled_indices = resampled_indices.flatten().tolist()\n",
        "\n",
        "        # resampled_train_data = torch.utils.data.Subset(train_data, resampled_indices)\n",
        "        # resampled_label_counts = Counter(resampled_labels)\n",
        "        # print(\"Resampled label distribution:\", resampled_label_counts)\n",
        "\n",
        "        #Use full dataset\n",
        "        train_data_loader = DataLoader(train_data, batch_size=default_batch_size, shuffle=True)\n",
        "        #test_dataloader = DataLoader(test_data, batch_size=default_batch_size) #No longer pass full dataloader\n",
        "        #geometric_weight = 0.1\n",
        "        #stage_1_weight = (1503/632)**geometric_weight\n",
        "        #stage_2_weight = (1503/258)**geometric_weight\n",
        "        normalized_weights = torch.tensor([1.0, 2, 1.3])\n",
        "        loss_fn = nn.CrossEntropyLoss(weight=normalized_weights.to(device))\n",
        "\n",
        "        # Initialize Model\n",
        "        model = BertClassifier(version, num_labels=3, num_Bottid_categories=num_Bottid_categories).to(device) # Initialize before weights, pass num_Bottid_categories here\n",
        "\n",
        "        train_dataloader = train_data_loader\n",
        "        val_dataloader = DataLoader(test_data, batch_size=default_batch_size) #Use full test_data as val for early stopping\n",
        "\n",
        "        #Set up the optimizer\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=default_lr, eps=default_eps)\n",
        "\n",
        "        #Calculate warmup steps based on epochs\n",
        "        total_steps = len(train_dataloader) * num_epochs\n",
        "        warmup_steps = int(warmup_proportion * total_steps)\n",
        "\n",
        "        #Get warmup + decay schedulers\n",
        "        warmup_scheduler, decay_scheduler = get_exponential_warmup_schedule(\n",
        "            optimizer,\n",
        "            warmup_steps,\n",
        "            default_lr,\n",
        "            target_lr,\n",
        "            num_epochs,\n",
        "            total_steps\n",
        "        )\n",
        "\n",
        "        #Train and evaluate\n",
        "        train_and_evaluate(model, train_dataloader, val_dataloader, optimizer, warmup_scheduler, decay_scheduler, epochs=num_epochs, loss_fn=loss_fn, num_classes=3, version=version, test_sets=test_sets)\n",
        "\n",
        "        #Evaluate on multiple test sets only after training + finding good model\n",
        "        evaluate_on_multiple_test_sets(model, test_sets, num_classes=3, version=version)\n",
        "        val_dataloader = DataLoader(test_data, batch_size=default_batch_size)\n",
        "        generate_classification_report(model, val_dataloader, num_classes=3, version=version) #Final report at the end."
      ],
      "metadata": {
        "id": "IwCGCkTINGyz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b1756370a57c41b78c7736f1c6921113",
            "1bd710613d5f458884d14e51ad5916b9",
            "d00ddcb6f076417bb0460e18ac4cc1b2",
            "6c0919fc99bf4d728b9d8283141f152c",
            "0ebee8f857b14a84a386da6ebe8fc213",
            "c352bce3ee974b0583805bdb8258dae3",
            "8bab3050021f400591a2660edfc2d037",
            "7849f8b69dc340a7920cb2ee21ec6b1b",
            "4e5b51f6f634442eb39611ad9102ea8c",
            "d59db225fb784e9993b02f38a9f5c622",
            "0e8365c045514578a3fb39ea56b65c8c",
            "07ff9d6debcb496ca9cdd223fd421f35",
            "8e62fcf8ebf2462997b548051644ade1",
            "3c43549e57b842d4b8651012a19dd712",
            "3d9a65f32efb4e30ac4964afb9c055f3",
            "6fef30e211ab4aa7b688fbbff6f83a9d",
            "240eb6fd556848ebb4be9017884ec482",
            "b5630fd3296d4840ae2084485a4f966b",
            "c281cba497ed47fc9906b599cc68b450",
            "3e157e12632b4a6a881485fa165fb959",
            "a5b060d2f45b4bca8443d3269afd20ce",
            "59896ef162a34005a8c18cd7fef245f5"
          ]
        },
        "outputId": "f2fe9a39-bb8e-4e07-9771-b45ea18e7aa4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "----- Running with bottleneckBERT -----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5582 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1756370a57c41b78c7736f1c6921113"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2393 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07ff9d6debcb496ca9cdd223fd421f35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original label distribution: Counter({0.0: 3465, 1.0: 1540, 2.0: 577})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at colaguo/bottleneckBERTsmall and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200, Training Loss: 1.1117, Validation Loss: 1.0975\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 1):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6385    0.7685    0.6975      1503\n",
            "           1     0.2470    0.1614    0.1952       632\n",
            "           2     0.0702    0.0465    0.0559       258\n",
            "\n",
            "    accuracy                         0.5303      2393\n",
            "   macro avg     0.3185    0.3255    0.3162      2393\n",
            "weighted avg     0.4738    0.5303    0.4957      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1155    235    113\n",
            "      1   484    102    46\n",
            "      2   170    76    12\n",
            "\n",
            "    \n",
            "New best F1 score: 0.4957 at epoch 1.\n",
            "Epoch 2/200, Training Loss: 1.0792, Validation Loss: 1.0470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 2):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6439    0.8962    0.7494      1503\n",
            "           1     0.2724    0.1297    0.1758       632\n",
            "           2     0.0000    0.0000    0.0000       258\n",
            "\n",
            "    accuracy                         0.5972      2393\n",
            "   macro avg     0.3054    0.3420    0.3084      2393\n",
            "weighted avg     0.4764    0.5972    0.5171      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1347    156    0\n",
            "      1   550    82    0\n",
            "      2   195    63    0\n",
            "\n",
            "    \n",
            "New best F1 score: 0.5171 at epoch 2.\n",
            "Epoch 3/200, Training Loss: 0.9979, Validation Loss: 0.9550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 3):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6305    0.9947    0.7718      1503\n",
            "           1     0.2727    0.0095    0.0183       632\n",
            "           2     0.0000    0.0000    0.0000       258\n",
            "\n",
            "    accuracy                         0.6272      2393\n",
            "   macro avg     0.3011    0.3347    0.2634      2393\n",
            "weighted avg     0.4681    0.6272    0.4896      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1495    8    0\n",
            "      1   626    6    0\n",
            "      2   250    8    0\n",
            "\n",
            "    \n",
            "Epoch 4/200, Training Loss: 0.9339, Validation Loss: 0.9063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 4):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7463    0.6733    0.7079      1503\n",
            "           1     0.3539    0.5807    0.4398       632\n",
            "           2     0.0000    0.0000    0.0000       258\n",
            "\n",
            "    accuracy                         0.5763      2393\n",
            "   macro avg     0.3667    0.4180    0.3826      2393\n",
            "weighted avg     0.5622    0.5763    0.5608      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1012    491    0\n",
            "      1   265    367    0\n",
            "      2   79    179    0\n",
            "\n",
            "    \n",
            "New best F1 score: 0.5608 at epoch 4.\n",
            "Epoch 5/200, Training Loss: 0.8802, Validation Loss: 0.8598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 5):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7816    0.6880    0.7318      1503\n",
            "           1     0.3804    0.6440    0.4783       632\n",
            "           2     0.0000    0.0000    0.0000       258\n",
            "\n",
            "    accuracy                         0.6022      2393\n",
            "   macro avg     0.3873    0.4440    0.4033      2393\n",
            "weighted avg     0.5913    0.6022    0.5859      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1034    469    0\n",
            "      1   225    407    0\n",
            "      2   64    194    0\n",
            "\n",
            "    \n",
            "New best F1 score: 0.5859 at epoch 5.\n",
            "Epoch 6/200, Training Loss: 0.8265, Validation Loss: 0.8504\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 6):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7431    0.8197    0.7795      1503\n",
            "           1     0.3978    0.4620    0.4275       632\n",
            "           2     1.0000    0.0039    0.0077       258\n",
            "\n",
            "    accuracy                         0.6373      2393\n",
            "   macro avg     0.7136    0.4285    0.4049      2393\n",
            "weighted avg     0.6796    0.6373    0.6033      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1232    271    0\n",
            "      1   340    292    0\n",
            "      2   86    171    1\n",
            "\n",
            "    \n",
            "New best F1 score: 0.6033 at epoch 6.\n",
            "Epoch 7/200, Training Loss: 0.7650, Validation Loss: 0.8217\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 7):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7626    0.7971    0.7794      1503\n",
            "           1     0.4250    0.5427    0.4767       632\n",
            "           2     0.9333    0.0543    0.1026       258\n",
            "\n",
            "    accuracy                         0.6498      2393\n",
            "   macro avg     0.7070    0.4647    0.4529      2393\n",
            "weighted avg     0.6918    0.6498    0.6265      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1198    304    1\n",
            "      1   289    343    0\n",
            "      2   84    160    14\n",
            "\n",
            "    \n",
            "New best F1 score: 0.6265 at epoch 7.\n",
            "Epoch 8/200, Training Loss: 0.7030, Validation Loss: 0.8240\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 8):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7641    0.8124    0.7875      1503\n",
            "           1     0.4424    0.5222    0.4790       632\n",
            "           2     0.8367    0.1589    0.2671       258\n",
            "\n",
            "    accuracy                         0.6653      2393\n",
            "   macro avg     0.6811    0.4978    0.5112      2393\n",
            "weighted avg     0.6869    0.6653    0.6499      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1221    278    4\n",
            "      1   298    330    4\n",
            "      2   79    138    41\n",
            "\n",
            "    \n",
            "New best F1 score: 0.6499 at epoch 8.\n",
            "Epoch 9/200, Training Loss: 0.6463, Validation Loss: 0.8022\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 9):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7897    0.7718    0.7806      1503\n",
            "           1     0.4475    0.6345    0.5249       632\n",
            "           2     0.8929    0.0969    0.1748       258\n",
            "\n",
            "    accuracy                         0.6628      2393\n",
            "   macro avg     0.7100    0.5011    0.4934      2393\n",
            "weighted avg     0.7104    0.6628    0.6478      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1160    342    1\n",
            "      1   229    401    2\n",
            "      2   80    153    25\n",
            "\n",
            "    \n",
            "Epoch 10/200, Training Loss: 0.5907, Validation Loss: 0.8251\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 10):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7772    0.8124    0.7944      1503\n",
            "           1     0.4881    0.5823    0.5310       632\n",
            "           2     0.8382    0.2209    0.3497       258\n",
            "\n",
            "    accuracy                         0.6878      2393\n",
            "   macro avg     0.7012    0.5385    0.5584      2393\n",
            "weighted avg     0.7074    0.6878    0.6769      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1221    276    6\n",
            "      1   259    368    5\n",
            "      2   91    110    57\n",
            "\n",
            "    \n",
            "New best F1 score: 0.6769 at epoch 10.\n",
            "Epoch 11/200, Training Loss: 0.5302, Validation Loss: 0.8324\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 11):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7766    0.8164    0.7960      1503\n",
            "           1     0.5162    0.5791    0.5459       632\n",
            "           2     0.7115    0.2868    0.4088       258\n",
            "\n",
            "    accuracy                         0.6966      2393\n",
            "   macro avg     0.6681    0.5608    0.5836      2393\n",
            "weighted avg     0.7008    0.6966    0.6882      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1227    259    17\n",
            "      1   253    366    13\n",
            "      2   100    84    74\n",
            "\n",
            "    \n",
            "New best F1 score: 0.6882 at epoch 11.\n",
            "Epoch 12/200, Training Loss: 0.4780, Validation Loss: 0.8475\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 12):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8014    0.7651    0.7828      1503\n",
            "           1     0.5151    0.5680    0.5403       632\n",
            "           2     0.5326    0.5388    0.5356       258\n",
            "\n",
            "    accuracy                         0.6887      2393\n",
            "   macro avg     0.6163    0.6240    0.6196      2393\n",
            "weighted avg     0.6968    0.6887    0.6921      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1150    287    66\n",
            "      1   217    359    56\n",
            "      2   68    51    139\n",
            "\n",
            "    \n",
            "New best F1 score: 0.6921 at epoch 12.\n",
            "Epoch 13/200, Training Loss: 0.4350, Validation Loss: 0.8656\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 13):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8263    0.7186    0.7687      1503\n",
            "           1     0.5156    0.6013    0.5551       632\n",
            "           2     0.4756    0.6434    0.5470       258\n",
            "\n",
            "    accuracy                         0.6795      2393\n",
            "   macro avg     0.6059    0.6544    0.6236      2393\n",
            "weighted avg     0.7065    0.6795    0.6884      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1080    314    109\n",
            "      1   178    380    74\n",
            "      2   49    43    166\n",
            "\n",
            "    \n",
            "Epoch 14/200, Training Loss: 0.4049, Validation Loss: 0.8718\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 14):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8035    0.7671    0.7849      1503\n",
            "           1     0.4981    0.6313    0.5569       632\n",
            "           2     0.6624    0.4031    0.5012       258\n",
            "\n",
            "    accuracy                         0.6920      2393\n",
            "   macro avg     0.6547    0.6005    0.6143      2393\n",
            "weighted avg     0.7076    0.6920    0.6941      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1153    317    33\n",
            "      1   213    399    20\n",
            "      2   69    85    104\n",
            "\n",
            "    \n",
            "New best F1 score: 0.6941 at epoch 14.\n",
            "Epoch 15/200, Training Loss: 0.3664, Validation Loss: 0.9019\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 15):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7992    0.7705    0.7846      1503\n",
            "           1     0.5013    0.6313    0.5588       632\n",
            "           2     0.6824    0.3915    0.4975       258\n",
            "\n",
            "    accuracy                         0.6929      2393\n",
            "   macro avg     0.6610    0.5978    0.6136      2393\n",
            "weighted avg     0.7079    0.6929    0.6940      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1158    315    30\n",
            "      1   216    399    17\n",
            "      2   75    82    101\n",
            "\n",
            "    \n",
            "Epoch 16/200, Training Loss: 0.3365, Validation Loss: 0.9038\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 16):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8071    0.7598    0.7827      1503\n",
            "           1     0.5149    0.6282    0.5659       632\n",
            "           2     0.6232    0.5000    0.5548       258\n",
            "\n",
            "    accuracy                         0.6970      2393\n",
            "   macro avg     0.6484    0.6293    0.6345      2393\n",
            "weighted avg     0.7101    0.6970    0.7009      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1142    311    50\n",
            "      1   207    397    28\n",
            "      2   66    63    129\n",
            "\n",
            "    \n",
            "New best F1 score: 0.7009 at epoch 16.\n",
            "Epoch 17/200, Training Loss: 0.3228, Validation Loss: 0.9405\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 17):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8184    0.7285    0.7709      1503\n",
            "           1     0.4724    0.6772    0.5566       632\n",
            "           2     0.6711    0.3876    0.4914       258\n",
            "\n",
            "    accuracy                         0.6782      2393\n",
            "   macro avg     0.6540    0.5978    0.6063      2393\n",
            "weighted avg     0.7111    0.6782    0.6841      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1095    376    32\n",
            "      1   187    428    17\n",
            "      2   56    102    100\n",
            "\n",
            "    \n",
            "Epoch 18/200, Training Loss: 0.2884, Validation Loss: 1.1106\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 18):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7489    0.8849    0.8112      1503\n",
            "           1     0.6266    0.4541    0.5266       632\n",
            "           2     0.6541    0.4031    0.4988       258\n",
            "\n",
            "    accuracy                         0.7192      2393\n",
            "   macro avg     0.6765    0.5807    0.6122      2393\n",
            "weighted avg     0.7064    0.7192    0.7024      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1330    140    33\n",
            "      1   323    287    22\n",
            "      2   123    31    104\n",
            "\n",
            "    \n",
            "New best F1 score: 0.7024 at epoch 18.\n",
            "Epoch 19/200, Training Loss: 0.2844, Validation Loss: 0.9837\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 19):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7919    0.8051    0.7984      1503\n",
            "           1     0.5552    0.5886    0.5714       632\n",
            "           2     0.6410    0.4845    0.5519       258\n",
            "\n",
            "    accuracy                         0.7133      2393\n",
            "   macro avg     0.6627    0.6261    0.6406      2393\n",
            "weighted avg     0.7131    0.7133    0.7119      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1210    251    42\n",
            "      1   232    372    28\n",
            "      2   86    47    125\n",
            "\n",
            "    \n",
            "New best F1 score: 0.7119 at epoch 19.\n",
            "Epoch 20/200, Training Loss: 0.2615, Validation Loss: 0.9724\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 20):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8319    0.7112    0.7669      1503\n",
            "           1     0.4926    0.6804    0.5714       632\n",
            "           2     0.5830    0.5310    0.5558       258\n",
            "\n",
            "    accuracy                         0.6837      2393\n",
            "   macro avg     0.6358    0.6409    0.6314      2393\n",
            "weighted avg     0.7154    0.6837    0.6925      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1069    370    64\n",
            "      1   168    430    34\n",
            "      2   48    73    137\n",
            "\n",
            "    \n",
            "Epoch 21/200, Training Loss: 0.2544, Validation Loss: 1.0410\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 21):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7970    0.7838    0.7903      1503\n",
            "           1     0.5474    0.5759    0.5613       632\n",
            "           2     0.5880    0.5698    0.5787       258\n",
            "\n",
            "    accuracy                         0.7058      2393\n",
            "   macro avg     0.6441    0.6432    0.6435      2393\n",
            "weighted avg     0.7086    0.7058    0.7070      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1178    258    67\n",
            "      1   232    364    36\n",
            "      2   68    43    147\n",
            "\n",
            "    \n",
            "Epoch 22/200, Training Loss: 0.2563, Validation Loss: 0.9974\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 22):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7941    0.8084    0.8012      1503\n",
            "           1     0.5557    0.5997    0.5769       632\n",
            "           2     0.6464    0.4535    0.5330       258\n",
            "\n",
            "    accuracy                         0.7150      2393\n",
            "   macro avg     0.6654    0.6205    0.6370      2393\n",
            "weighted avg     0.7152    0.7150    0.7130      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1215    250    38\n",
            "      1   227    379    26\n",
            "      2   88    53    117\n",
            "\n",
            "    \n",
            "New best F1 score: 0.7130 at epoch 22.\n",
            "Epoch 23/200, Training Loss: 0.2382, Validation Loss: 1.0291\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 23):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8222    0.7292    0.7729      1503\n",
            "           1     0.5000    0.6677    0.5718       632\n",
            "           2     0.6157    0.5155    0.5612       258\n",
            "\n",
            "    accuracy                         0.6899      2393\n",
            "   macro avg     0.6460    0.6375    0.6353      2393\n",
            "weighted avg     0.7149    0.6899    0.6970      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1096    359    48\n",
            "      1   175    422    35\n",
            "      2   62    63    133\n",
            "\n",
            "    \n",
            "Epoch 24/200, Training Loss: 0.2132, Validation Loss: 1.1313\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 24):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7895    0.8137    0.8014      1503\n",
            "           1     0.5514    0.5775    0.5641       632\n",
            "           2     0.6593    0.4651    0.5455       258\n",
            "\n",
            "    accuracy                         0.7137      2393\n",
            "   macro avg     0.6667    0.6188    0.6370      2393\n",
            "weighted avg     0.7126    0.7137    0.7112      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1223    245    35\n",
            "      1   240    365    27\n",
            "      2   86    52    120\n",
            "\n",
            "    \n",
            "Epoch 25/200, Training Loss: 0.2009, Validation Loss: 1.2573\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 25):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7943    0.7911    0.7927      1503\n",
            "           1     0.5371    0.5949    0.5646       632\n",
            "           2     0.6071    0.4612    0.5242       258\n",
            "\n",
            "    accuracy                         0.7037      2393\n",
            "   macro avg     0.6462    0.6158    0.6272      2393\n",
            "weighted avg     0.7062    0.7037    0.7035      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1189    270    44\n",
            "      1   223    376    33\n",
            "      2   85    54    119\n",
            "\n",
            "    \n",
            "Epoch 26/200, Training Loss: 0.1928, Validation Loss: 1.3505\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 26):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7720    0.8516    0.8099      1503\n",
            "           1     0.6026    0.5063    0.5503       632\n",
            "           2     0.6422    0.5078    0.5671       258\n",
            "\n",
            "    accuracy                         0.7234      2393\n",
            "   macro avg     0.6723    0.6219    0.6424      2393\n",
            "weighted avg     0.7133    0.7234    0.7151      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1280    180    43\n",
            "      1   282    320    30\n",
            "      2   96    31    131\n",
            "\n",
            "    \n",
            "New best F1 score: 0.7151 at epoch 26.\n",
            "Epoch 27/200, Training Loss: 0.1906, Validation Loss: 1.3306\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 27):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8004    0.7818    0.7910      1503\n",
            "           1     0.5332    0.6092    0.5687       632\n",
            "           2     0.6059    0.4767    0.5336       258\n",
            "\n",
            "    accuracy                         0.7033      2393\n",
            "   macro avg     0.6465    0.6226    0.6311      2393\n",
            "weighted avg     0.7089    0.7033    0.7045      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1175    281    47\n",
            "      1   214    385    33\n",
            "      2   79    56    123\n",
            "\n",
            "    \n",
            "Epoch 28/200, Training Loss: 0.1805, Validation Loss: 1.3556\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 28):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7757    0.8649    0.8179      1503\n",
            "           1     0.6252    0.5332    0.5756       632\n",
            "           2     0.6461    0.4457    0.5275       258\n",
            "\n",
            "    accuracy                         0.7321      2393\n",
            "   macro avg     0.6823    0.6146    0.6403      2393\n",
            "weighted avg     0.7220    0.7321    0.7226      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1300    171    32\n",
            "      1   264    337    31\n",
            "      2   112    31    115\n",
            "\n",
            "    \n",
            "New best F1 score: 0.7226 at epoch 28.\n",
            "Epoch 29/200, Training Loss: 0.1729, Validation Loss: 1.4056\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 29):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7808    0.8011    0.7908      1503\n",
            "           1     0.5141    0.6044    0.5556       632\n",
            "           2     0.6667    0.2791    0.3934       258\n",
            "\n",
            "    accuracy                         0.6929      2393\n",
            "   macro avg     0.6539    0.5615    0.5800      2393\n",
            "weighted avg     0.6981    0.6929    0.6859      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1204    278    21\n",
            "      1   235    382    15\n",
            "      2   103    83    72\n",
            "\n",
            "    \n",
            "Epoch 30/200, Training Loss: 0.1788, Validation Loss: 1.2843\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 30):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7948    0.8064    0.8005      1503\n",
            "           1     0.5515    0.5934    0.5716       632\n",
            "           2     0.6543    0.4767    0.5516       258\n",
            "\n",
            "    accuracy                         0.7146      2393\n",
            "   macro avg     0.6668    0.6255    0.6412      2393\n",
            "weighted avg     0.7154    0.7146    0.7132      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1212    260    31\n",
            "      1   223    375    34\n",
            "      2   90    45    123\n",
            "\n",
            "    \n",
            "Epoch 31/200, Training Loss: 0.1781, Validation Loss: 1.3105\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 31):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7913    0.7898    0.7905      1503\n",
            "           1     0.5116    0.6266    0.5633       632\n",
            "           2     0.7395    0.3411    0.4668       258\n",
            "\n",
            "    accuracy                         0.6983      2393\n",
            "   macro avg     0.6808    0.5858    0.6069      2393\n",
            "weighted avg     0.7119    0.6983    0.6956      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1187    300    16\n",
            "      1   221    396    15\n",
            "      2   92    78    88\n",
            "\n",
            "    \n",
            "Epoch 32/200, Training Loss: 0.1685, Validation Loss: 1.4256\n",
            "\n",
            "    Classification Report (Val, Version: bottleneckBERT, Epoch 32):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8028    0.7911    0.7969      1503\n",
            "           1     0.5431    0.6076    0.5736       632\n",
            "           2     0.6146    0.4884    0.5443       258\n",
            "\n",
            "    accuracy                         0.7100      2393\n",
            "   macro avg     0.6535    0.6290    0.6383      2393\n",
            "weighted avg     0.7140    0.7100    0.7107      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1189    264    50\n",
            "      1   219    384    29\n",
            "      2   73    59    126\n",
            "\n",
            "    \n",
            "Early stopping triggered.\n",
            "Best model (version bottleneckBERT) saved to model_output/model_version_bottleneckBERT.pth with F1 0.7226\n",
            "Evaluating on multiple test sets...\n",
            "\n",
            "    Classification Report (Test Set 1, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8011    0.7803    0.7906      1352\n",
            "           1     0.5370    0.6127    0.5724       568\n",
            "           2     0.5936    0.4784    0.5298       232\n",
            "\n",
            "    accuracy                         0.7035      2152\n",
            "   macro avg     0.6439    0.6238    0.6309      2152\n",
            "weighted avg     0.7090    0.7035    0.7049      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1055    247    50\n",
            "      1   194    348    26\n",
            "      2   68    53    111\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 2, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7979    0.7885    0.7932      1352\n",
            "           1     0.5377    0.6021    0.5681       568\n",
            "           2     0.6222    0.4828    0.5437       232\n",
            "\n",
            "    accuracy                         0.7063      2152\n",
            "   macro avg     0.6526    0.6244    0.6350      2152\n",
            "weighted avg     0.7103    0.7063    0.7069      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1066    240    46\n",
            "      1   204    342    22\n",
            "      2   66    54    112\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 3, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8062    0.7936    0.7999      1352\n",
            "           1     0.5554    0.6268    0.5889       568\n",
            "           2     0.6167    0.4784    0.5388       232\n",
            "\n",
            "    accuracy                         0.7156      2152\n",
            "   macro avg     0.6594    0.6329    0.6425      2152\n",
            "weighted avg     0.7195    0.7156    0.7160      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1073    234    45\n",
            "      1   188    356    24\n",
            "      2   70    51    111\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 4, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8023    0.7862    0.7942      1352\n",
            "           1     0.5334    0.6039    0.5665       568\n",
            "           2     0.6141    0.4871    0.5433       232\n",
            "\n",
            "    accuracy                         0.7059      2152\n",
            "   macro avg     0.6499    0.6257    0.6346      2152\n",
            "weighted avg     0.7110    0.7059    0.7070      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1063    246    43\n",
            "      1   197    343    28\n",
            "      2   65    54    113\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 5, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8016    0.7922    0.7969      1352\n",
            "           1     0.5398    0.5968    0.5669       568\n",
            "           2     0.6011    0.4871    0.5381       232\n",
            "\n",
            "    accuracy                         0.7077      2152\n",
            "   macro avg     0.6475    0.6254    0.6340      2152\n",
            "weighted avg     0.7109    0.7077    0.7083      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1071    234    47\n",
            "      1   201    339    28\n",
            "      2   64    55    113\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 6, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8001    0.7936    0.7969      1352\n",
            "           1     0.5404    0.6004    0.5688       568\n",
            "           2     0.6167    0.4784    0.5388       232\n",
            "\n",
            "    accuracy                         0.7086      2152\n",
            "   macro avg     0.6524    0.6241    0.6348      2152\n",
            "weighted avg     0.7118    0.7086    0.7089      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1073    237    42\n",
            "      1   200    341    27\n",
            "      2   68    53    111\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 7, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8051    0.7973    0.8012      1352\n",
            "           1     0.5492    0.6092    0.5776       568\n",
            "           2     0.6230    0.4914    0.5494       232\n",
            "\n",
            "    accuracy                         0.7147      2152\n",
            "   macro avg     0.6591    0.6326    0.6427      2152\n",
            "weighted avg     0.7179    0.7147    0.7150      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1078    231    43\n",
            "      1   196    346    26\n",
            "      2   65    53    114\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 8, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8014    0.7877    0.7945      1352\n",
            "           1     0.5368    0.6039    0.5684       568\n",
            "           2     0.6196    0.4914    0.5481       232\n",
            "\n",
            "    accuracy                         0.7072      2152\n",
            "   macro avg     0.6526    0.6277    0.6370      2152\n",
            "weighted avg     0.7119    0.7072    0.7082      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1065    241    46\n",
            "      1   201    343    24\n",
            "      2   63    55    114\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 9, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8063    0.7944    0.8003      1352\n",
            "           1     0.5472    0.6127    0.5781       568\n",
            "           2     0.6033    0.4784    0.5337       232\n",
            "\n",
            "    accuracy                         0.7124      2152\n",
            "   macro avg     0.6522    0.6285    0.6373      2152\n",
            "weighted avg     0.7160    0.7124    0.7129      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1074    232    46\n",
            "      1   193    348    27\n",
            "      2   65    56    111\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 10, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8037    0.7936    0.7987      1352\n",
            "           1     0.5462    0.6144    0.5783       568\n",
            "           2     0.6292    0.4828    0.5463       232\n",
            "\n",
            "    accuracy                         0.7128      2152\n",
            "   macro avg     0.6597    0.6303    0.6411      2152\n",
            "weighted avg     0.7169    0.7128    0.7133      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1073    235    44\n",
            "      1   197    349    22\n",
            "      2   65    55    112\n",
            "\n",
            "    \n",
            "Averaged performance across all test sets:\n",
            "precision_0_avg: 0.8026 +/- 0.0026\n",
            "precision_0_std: 0.0026 +/- 0.0026\n",
            "recall_0_avg: 0.7908 +/- 0.0048\n",
            "recall_0_std: 0.0048 +/- 0.0048\n",
            "f1-score_0_avg: 0.7966 +/- 0.0033\n",
            "f1-score_0_std: 0.0033 +/- 0.0033\n",
            "support_0_avg: 1352.0000 +/- 0.0000\n",
            "support_0_std: 0.0000 +/- 0.0000\n",
            "precision_1_avg: 0.5423 +/- 0.0065\n",
            "precision_1_std: 0.0065 +/- 0.0065\n",
            "recall_1_avg: 0.6083 +/- 0.0083\n",
            "recall_1_std: 0.0083 +/- 0.0083\n",
            "f1-score_1_avg: 0.5734 +/- 0.0069\n",
            "f1-score_1_std: 0.0069 +/- 0.0069\n",
            "support_1_avg: 568.0000 +/- 0.0000\n",
            "support_1_std: 0.0000 +/- 0.0000\n",
            "precision_2_avg: 0.6139 +/- 0.0106\n",
            "precision_2_std: 0.0106 +/- 0.0106\n",
            "recall_2_avg: 0.4836 +/- 0.0050\n",
            "recall_2_std: 0.0050 +/- 0.0050\n",
            "f1-score_2_avg: 0.5410 +/- 0.0060\n",
            "f1-score_2_std: 0.0060 +/- 0.0060\n",
            "support_2_avg: 232.0000 +/- 0.0000\n",
            "support_2_std: 0.0000 +/- 0.0000\n",
            "\n",
            "Evaluation on multiple test sets complete.\n",
            "Training completed. Best F1 score: 0.7226 achieved at epoch 28.\n",
            "\n",
            "    Classification Report (Test Set 1, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8011    0.7803    0.7906      1352\n",
            "           1     0.5370    0.6127    0.5724       568\n",
            "           2     0.5936    0.4784    0.5298       232\n",
            "\n",
            "    accuracy                         0.7035      2152\n",
            "   macro avg     0.6439    0.6238    0.6309      2152\n",
            "weighted avg     0.7090    0.7035    0.7049      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1055    247    50\n",
            "      1   194    348    26\n",
            "      2   68    53    111\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 2, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7979    0.7885    0.7932      1352\n",
            "           1     0.5377    0.6021    0.5681       568\n",
            "           2     0.6222    0.4828    0.5437       232\n",
            "\n",
            "    accuracy                         0.7063      2152\n",
            "   macro avg     0.6526    0.6244    0.6350      2152\n",
            "weighted avg     0.7103    0.7063    0.7069      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1066    240    46\n",
            "      1   204    342    22\n",
            "      2   66    54    112\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 3, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8062    0.7936    0.7999      1352\n",
            "           1     0.5554    0.6268    0.5889       568\n",
            "           2     0.6167    0.4784    0.5388       232\n",
            "\n",
            "    accuracy                         0.7156      2152\n",
            "   macro avg     0.6594    0.6329    0.6425      2152\n",
            "weighted avg     0.7195    0.7156    0.7160      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1073    234    45\n",
            "      1   188    356    24\n",
            "      2   70    51    111\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 4, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8023    0.7862    0.7942      1352\n",
            "           1     0.5334    0.6039    0.5665       568\n",
            "           2     0.6141    0.4871    0.5433       232\n",
            "\n",
            "    accuracy                         0.7059      2152\n",
            "   macro avg     0.6499    0.6257    0.6346      2152\n",
            "weighted avg     0.7110    0.7059    0.7070      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1063    246    43\n",
            "      1   197    343    28\n",
            "      2   65    54    113\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 5, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8016    0.7922    0.7969      1352\n",
            "           1     0.5398    0.5968    0.5669       568\n",
            "           2     0.6011    0.4871    0.5381       232\n",
            "\n",
            "    accuracy                         0.7077      2152\n",
            "   macro avg     0.6475    0.6254    0.6340      2152\n",
            "weighted avg     0.7109    0.7077    0.7083      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1071    234    47\n",
            "      1   201    339    28\n",
            "      2   64    55    113\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 6, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8001    0.7936    0.7969      1352\n",
            "           1     0.5404    0.6004    0.5688       568\n",
            "           2     0.6167    0.4784    0.5388       232\n",
            "\n",
            "    accuracy                         0.7086      2152\n",
            "   macro avg     0.6524    0.6241    0.6348      2152\n",
            "weighted avg     0.7118    0.7086    0.7089      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1073    237    42\n",
            "      1   200    341    27\n",
            "      2   68    53    111\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 7, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8051    0.7973    0.8012      1352\n",
            "           1     0.5492    0.6092    0.5776       568\n",
            "           2     0.6230    0.4914    0.5494       232\n",
            "\n",
            "    accuracy                         0.7147      2152\n",
            "   macro avg     0.6591    0.6326    0.6427      2152\n",
            "weighted avg     0.7179    0.7147    0.7150      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1078    231    43\n",
            "      1   196    346    26\n",
            "      2   65    53    114\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 8, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8014    0.7877    0.7945      1352\n",
            "           1     0.5368    0.6039    0.5684       568\n",
            "           2     0.6196    0.4914    0.5481       232\n",
            "\n",
            "    accuracy                         0.7072      2152\n",
            "   macro avg     0.6526    0.6277    0.6370      2152\n",
            "weighted avg     0.7119    0.7072    0.7082      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1065    241    46\n",
            "      1   201    343    24\n",
            "      2   63    55    114\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 9, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8063    0.7944    0.8003      1352\n",
            "           1     0.5472    0.6127    0.5781       568\n",
            "           2     0.6033    0.4784    0.5337       232\n",
            "\n",
            "    accuracy                         0.7124      2152\n",
            "   macro avg     0.6522    0.6285    0.6373      2152\n",
            "weighted avg     0.7160    0.7124    0.7129      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1074    232    46\n",
            "      1   193    348    27\n",
            "      2   65    56    111\n",
            "\n",
            "    \n",
            "\n",
            "    Classification Report (Test Set 10, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8037    0.7936    0.7987      1352\n",
            "           1     0.5462    0.6144    0.5783       568\n",
            "           2     0.6292    0.4828    0.5463       232\n",
            "\n",
            "    accuracy                         0.7128      2152\n",
            "   macro avg     0.6597    0.6303    0.6411      2152\n",
            "weighted avg     0.7169    0.7128    0.7133      2152\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1073    235    44\n",
            "      1   197    349    22\n",
            "      2   65    55    112\n",
            "\n",
            "    \n",
            "Averaged performance across all test sets:\n",
            "precision_0_avg: 0.8026 +/- 0.0026\n",
            "precision_0_std: 0.0026 +/- 0.0026\n",
            "recall_0_avg: 0.7908 +/- 0.0048\n",
            "recall_0_std: 0.0048 +/- 0.0048\n",
            "f1-score_0_avg: 0.7966 +/- 0.0033\n",
            "f1-score_0_std: 0.0033 +/- 0.0033\n",
            "support_0_avg: 1352.0000 +/- 0.0000\n",
            "support_0_std: 0.0000 +/- 0.0000\n",
            "precision_1_avg: 0.5423 +/- 0.0065\n",
            "precision_1_std: 0.0065 +/- 0.0065\n",
            "recall_1_avg: 0.6083 +/- 0.0083\n",
            "recall_1_std: 0.0083 +/- 0.0083\n",
            "f1-score_1_avg: 0.5734 +/- 0.0069\n",
            "f1-score_1_std: 0.0069 +/- 0.0069\n",
            "support_1_avg: 568.0000 +/- 0.0000\n",
            "support_1_std: 0.0000 +/- 0.0000\n",
            "precision_2_avg: 0.6139 +/- 0.0106\n",
            "precision_2_std: 0.0106 +/- 0.0106\n",
            "recall_2_avg: 0.4836 +/- 0.0050\n",
            "recall_2_std: 0.0050 +/- 0.0050\n",
            "f1-score_2_avg: 0.5410 +/- 0.0060\n",
            "f1-score_2_std: 0.0060 +/- 0.0060\n",
            "support_2_avg: 232.0000 +/- 0.0000\n",
            "support_2_std: 0.0000 +/- 0.0000\n",
            "\n",
            "\n",
            "    Classification Report (Test, Version: bottleneckBERT, Epoch Final):\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8028    0.7911    0.7969      1503\n",
            "           1     0.5431    0.6076    0.5736       632\n",
            "           2     0.6146    0.4884    0.5443       258\n",
            "\n",
            "    accuracy                         0.7100      2393\n",
            "   macro avg     0.6535    0.6290    0.6383      2393\n",
            "weighted avg     0.7140    0.7100    0.7107      2393\n",
            "\n",
            "\n",
            "    \n",
            "Confusion Matrix:\n",
            "            Predicted\n",
            "           0    1    2\n",
            "Actual\n",
            "      0   1189    264    50\n",
            "      1   219    384    29\n",
            "      2   73    59    126\n",
            "\n",
            "    \n"
          ]
        }
      ]
    }
  ]
}