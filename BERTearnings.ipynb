{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c8b63e6fd6274b30832b0bad335a4c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfadaf82cb784707aaa4d1f80de100a2",
              "IPY_MODEL_986be3bf16ab46ed8e09f4744b134c8d",
              "IPY_MODEL_a4196d380bdd4ea8a9d94d23dacef9ca"
            ],
            "layout": "IPY_MODEL_43682361065e46c49015e622ab02f8ca"
          }
        },
        "bfadaf82cb784707aaa4d1f80de100a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3b10b2fb4b74c06bbea04b5ec672281",
            "placeholder": "​",
            "style": "IPY_MODEL_adb9c29d672e4940bb32ae6d7ca88089",
            "value": "Map: 100%"
          }
        },
        "986be3bf16ab46ed8e09f4744b134c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a80afe433724a79b6f670afa0bb17d1",
            "max": 5582,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38bf38b7e5cf4e998db16ef29fcc7e88",
            "value": 5582
          }
        },
        "a4196d380bdd4ea8a9d94d23dacef9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c291fc65e5747d1915b8aae05abfd7e",
            "placeholder": "​",
            "style": "IPY_MODEL_527a491b0bb84bf399b749f521914352",
            "value": " 5582/5582 [00:03&lt;00:00, 1760.84 examples/s]"
          }
        },
        "43682361065e46c49015e622ab02f8ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3b10b2fb4b74c06bbea04b5ec672281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adb9c29d672e4940bb32ae6d7ca88089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a80afe433724a79b6f670afa0bb17d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38bf38b7e5cf4e998db16ef29fcc7e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c291fc65e5747d1915b8aae05abfd7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "527a491b0bb84bf399b749f521914352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d90cd26ad23481b9bb5619ec81debe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4917b2dae613402c8cfd9431244085a7",
              "IPY_MODEL_593f7d7fdeb94293975e4a63f07a006d",
              "IPY_MODEL_6090444398ab4391be2724a215094c21"
            ],
            "layout": "IPY_MODEL_75259fadab574e598b63b872ccdb39b7"
          }
        },
        "4917b2dae613402c8cfd9431244085a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b1b0b79b7874921abcdd5fb2ab56765",
            "placeholder": "​",
            "style": "IPY_MODEL_3391c78387ef4838bf089e794aa724e0",
            "value": "Map: 100%"
          }
        },
        "593f7d7fdeb94293975e4a63f07a006d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98631da21550469fbbc52e47a11a898a",
            "max": 2393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3a9b2d9e80843ecb245ddf68355083d",
            "value": 2393
          }
        },
        "6090444398ab4391be2724a215094c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6452fdbedca46d991c90162b632c7fa",
            "placeholder": "​",
            "style": "IPY_MODEL_364852579f8f464eb6c9aacf36dabfe1",
            "value": " 2393/2393 [00:01&lt;00:00, 1919.19 examples/s]"
          }
        },
        "75259fadab574e598b63b872ccdb39b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b1b0b79b7874921abcdd5fb2ab56765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3391c78387ef4838bf089e794aa724e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98631da21550469fbbc52e47a11a898a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3a9b2d9e80843ecb245ddf68355083d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6452fdbedca46d991c90162b632c7fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "364852579f8f464eb6c9aacf36dabfe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/col-a-guo/guo_chen_jang_ms_project/blob/main/BERTearnings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NMT74j2CWx4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ccb953-e53c-4138-f8b6-1ad428c0b709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.12/dist-packages (0.0)\n",
            "Requirement already satisfied: pytorch_metric_learning in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (from imblearn) (0.14.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers datasets torchmetrics scikit-learn numpy huggingface-hub pandas imblearn pytorch_metric_learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "qfI3GWR8L08v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76abcfc6-5c45-4532-b6ca-04a1c5fd74ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QRwF2e0Jfmh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "FILE_PATH = '/content/drive/MyDrive/BERTearningsdata/'\n",
        "print(os.listdir('/content/drive/MyDrive/BERTearningsdata/'))"
      ],
      "metadata": {
        "id": "sSCWyzOyMlYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76f723c-26f7-4c02-badb-e679ad4e6578"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train_sept22_combined.csv', 'test_sept22_combined.csv', 'sept22_combined.csv', 'sept1_combined.csv', 'test_sept1_combined.csv', 'train_sept1_combined.csv', 'sept22_combined.gsheet', 'train_nov25_combined.csv', 'test_nov25_combined.csv', 'nov25_combined.csv', 'test_dec1_combined.csv', 'train_dec1_combined.csv', 'dec1_combined.csv', 'feature_importance_bottleneckBERT.png', 'feature_importance_bottleneckBERT.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from transformers import get_scheduler\n",
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "import torchmetrics\n",
        "from pytorch_metric_learning import losses\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import random\n",
        "import numpy as np\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from torch.optim.lr_scheduler import LambdaLR, ExponentialLR\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    seed_value = 1\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "    version_list = [\"bottleneckBERT\"]\n",
        "    # Default hyperparameters\n",
        "    default_lr = 2e-5\n",
        "    target_lr = 9e-6\n",
        "    default_eps = 6.748313060587885e-08\n",
        "    default_batch_size = 32\n",
        "    num_epochs = 200\n",
        "    patience = 3\n",
        "    warmup_proportion = 0.2\n",
        "    supcon_weight = 0.1\n",
        "    supcon_temperature = 0.1\n",
        "\n",
        "    # Feature names for importance analysis\n",
        "    FEATURE_NAMES = ['year', 'word_count', 'scarcity', 'nonuniform_progress',\n",
        "                     'performance_constraints', 'user_heterogeneity', 'cognitive',\n",
        "                     'external', 'internal', 'coordination', 'transactional',\n",
        "                     'technical', 'demand']\n",
        "\n",
        "    def compute_feature_importance(model, dataloader, tokenizer, num_features=13, num_Bottid_categories=29, max_samples=100):\n",
        "        \"\"\"\n",
        "        Compute feature importance using gradient-based method.\n",
        "\n",
        "        Args:\n",
        "            model: Trained model\n",
        "            dataloader: DataLoader for the dataset\n",
        "            tokenizer: Tokenizer to decode tokens\n",
        "            num_features: Number of numerical features\n",
        "            num_Bottid_categories: Number of Bottid categories\n",
        "            max_samples: Maximum number of samples to analyze for text importance\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with feature importances\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        # Store gradients for each feature\n",
        "        feature_gradients = torch.zeros(num_features).to(device)\n",
        "        bottid_gradients = torch.zeros(num_Bottid_categories).to(device)\n",
        "        num_samples = 0\n",
        "\n",
        "        # For text importance: collect token-level importance scores\n",
        "        token_importance_scores = []\n",
        "        sample_texts = []\n",
        "        sample_predictions = []\n",
        "\n",
        "        for batch_idx, batch in enumerate(dataloader):\n",
        "            input_ids, attention_mask, features, Bottid_encoded, labels = [t.to(device) for t in batch]\n",
        "\n",
        "            # Enable gradient computation for features\n",
        "            features.requires_grad = True\n",
        "            Bottid_encoded.requires_grad = True\n",
        "\n",
        "            # For text analysis, we need to embed the tokens\n",
        "            if batch_idx < max_samples // default_batch_size:  # Limit samples for text analysis\n",
        "                # Get embeddings from BERT's embedding layer\n",
        "                embeddings = model.bert.embeddings(input_ids=input_ids)\n",
        "                embeddings.retain_grad()\n",
        "\n",
        "                # Forward pass through the rest of the model\n",
        "                outputs = model.bert(inputs_embeds=embeddings, attention_mask=attention_mask)\n",
        "                last_hidden_state = outputs.last_hidden_state\n",
        "                pooled_output = model.pooling(last_hidden_state.permute(0, 2, 1)).squeeze(-1)\n",
        "                bert_output = model.cls_head(pooled_output)\n",
        "                linear_features_output = model.linear_features(features)\n",
        "                Bottid_output = model.linear_Bottid(Bottid_encoded)\n",
        "                combined_output = torch.cat((bert_output, linear_features_output, Bottid_output), dim=1)\n",
        "                linear_layer_output = model.linear_combined_layer(combined_output)\n",
        "                logits = model.final_classifier(linear_layer_output)\n",
        "            else:\n",
        "                # Standard forward pass for numerical features only\n",
        "                logits, _ = model(input_ids, attention_mask, features, Bottid_encoded)\n",
        "\n",
        "            # Get predictions\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            # Compute gradient of prediction w.r.t. features\n",
        "            for i in range(len(labels)):\n",
        "                model.zero_grad()\n",
        "                logits[i, preds[i]].backward(retain_graph=True)\n",
        "\n",
        "                # Accumulate absolute gradients for numerical features\n",
        "                if features.grad is not None:\n",
        "                    feature_gradients += torch.abs(features.grad[i])\n",
        "                if Bottid_encoded.grad is not None:\n",
        "                    bottid_gradients += torch.abs(Bottid_encoded.grad[i])\n",
        "\n",
        "                # For text importance (limited samples)\n",
        "                if batch_idx < max_samples // default_batch_size and embeddings.grad is not None:\n",
        "                    # Calculate token importance as L2 norm of gradients\n",
        "                    token_grads = embeddings.grad[i]  # [seq_len, hidden_dim]\n",
        "                    token_importance = torch.norm(token_grads, dim=1).cpu().numpy()  # [seq_len]\n",
        "\n",
        "                    # Get the actual tokens\n",
        "                    tokens = tokenizer.convert_ids_to_tokens(input_ids[i].cpu().numpy())\n",
        "\n",
        "                    # Store results\n",
        "                    token_importance_scores.append(token_importance)\n",
        "                    sample_texts.append(tokens)\n",
        "                    sample_predictions.append(preds[i].item())\n",
        "\n",
        "                # Clear gradients\n",
        "                features.grad = None\n",
        "                Bottid_encoded.grad = None\n",
        "                if batch_idx < max_samples // default_batch_size:\n",
        "                    embeddings.grad = None\n",
        "\n",
        "            num_samples += len(labels)\n",
        "\n",
        "            if batch_idx >= max_samples // default_batch_size:\n",
        "                break  # Stop early for efficiency\n",
        "\n",
        "        # Average the gradients\n",
        "        feature_gradients = feature_gradients / num_samples\n",
        "        bottid_gradients = bottid_gradients / num_samples\n",
        "\n",
        "        return {\n",
        "            'feature_importance': feature_gradients.cpu().numpy(),\n",
        "            'bottid_importance': bottid_gradients.cpu().numpy(),\n",
        "            'token_importance_scores': token_importance_scores,\n",
        "            'sample_texts': sample_texts,\n",
        "            'sample_predictions': sample_predictions\n",
        "        }\n",
        "\n",
        "    def plot_feature_importance(importance_dict, feature_names, save_path, version):\n",
        "        \"\"\"\n",
        "        Plot and save feature importance visualizations.\n",
        "\n",
        "        Args:\n",
        "            importance_dict: Dictionary with feature importances\n",
        "            feature_names: List of feature names\n",
        "            save_path: Path to save the plots\n",
        "            version: Model version string\n",
        "        \"\"\"\n",
        "        # Create figure with subplots\n",
        "        fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "        # Plot numerical features importance\n",
        "        feature_imp = importance_dict['feature_importance']\n",
        "        sorted_idx = np.argsort(feature_imp)[::-1]\n",
        "\n",
        "        axes[0].barh(range(len(feature_names)), feature_imp[sorted_idx])\n",
        "        axes[0].set_yticks(range(len(feature_names)))\n",
        "        axes[0].set_yticklabels([feature_names[i] for i in sorted_idx])\n",
        "        axes[0].set_xlabel('Importance Score')\n",
        "        axes[0].set_title(f'Feature Importance - Numerical Features ({version})')\n",
        "        axes[0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "        # Plot Bottid categories importance (top 20)\n",
        "        bottid_imp = importance_dict['bottid_importance']\n",
        "        top_n = min(20, len(bottid_imp))\n",
        "        sorted_bottid_idx = np.argsort(bottid_imp)[::-1][:top_n]\n",
        "\n",
        "        axes[1].barh(range(top_n), bottid_imp[sorted_bottid_idx])\n",
        "        axes[1].set_yticks(range(top_n))\n",
        "        axes[1].set_yticklabels([f'Bottid_{i}' for i in sorted_bottid_idx])\n",
        "        axes[1].set_xlabel('Importance Score')\n",
        "        axes[1].set_title(f'Feature Importance - Top {top_n} Bottid Categories ({version})')\n",
        "        axes[1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save the plot\n",
        "        plot_filename = os.path.join(save_path, f'feature_importance_inc_token_{version}.png')\n",
        "        plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Feature importance plot saved to {plot_filename}\")\n",
        "        plt.close()\n",
        "\n",
        "        # Save importance scores to CSV\n",
        "        csv_filename = os.path.join(save_path, f'feature_importance_inc_token_{version}.csv')\n",
        "\n",
        "        # Create DataFrame for numerical features\n",
        "        df_features = pd.DataFrame({\n",
        "            'Feature': feature_names,\n",
        "            'Importance': feature_imp\n",
        "        }).sort_values('Importance', ascending=False)\n",
        "\n",
        "        # Create DataFrame for Bottid features\n",
        "        df_bottid = pd.DataFrame({\n",
        "            'Feature': [f'Bottid_{i}' for i in range(len(bottid_imp))],\n",
        "            'Importance': bottid_imp\n",
        "        }).sort_values('Importance', ascending=False)\n",
        "\n",
        "        # Combine and save\n",
        "        with open(csv_filename, 'w') as f:\n",
        "            f.write(f\"Feature Importance Analysis - {version}\\n\\n\")\n",
        "            f.write(\"Numerical Features:\\n\")\n",
        "            df_features.to_csv(f, index=False)\n",
        "            f.write(\"\\n\\nBottid Categories:\\n\")\n",
        "            df_bottid.to_csv(f, index=False)\n",
        "\n",
        "        print(f\"Feature importance scores saved to {csv_filename}\")\n",
        "\n",
        "        return df_features, df_bottid\n",
        "\n",
        "    # function to generate classification report for multi-class\n",
        "    def generate_classification_report(model, dataloader, num_classes, epoch=None, version=None, split_name=\"Test\"):\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                input_ids, attention_mask, features, Bottid_encoded, labels = [t.to(device) for t in batch]\n",
        "                logits, _ = model(input_ids, attention_mask, features, Bottid_encoded)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        all_preds = np.array(all_preds)\n",
        "        all_labels = np.array(all_labels)\n",
        "\n",
        "        report = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(num_classes)], digits=4)\n",
        "\n",
        "        cm = confusion_matrix(all_labels, all_preds, labels=list(range(num_classes)))\n",
        "        cm_report = \"\\nConfusion Matrix:\\n\"\n",
        "        cm_report += \"            Predicted\\n\"\n",
        "        cm_report += \"           \" + \"    \".join(map(str, range(num_classes))) + \"\\n\"\n",
        "        cm_report += \"Actual\\n\"\n",
        "        for i, row in enumerate(cm):\n",
        "            cm_report += f\"      {i}   \" + \"    \".join(map(str, row)) + \"\\n\"\n",
        "\n",
        "        final_report = f\"\"\"\n",
        "    Classification Report ({split_name}, Version: {version}, Epoch {epoch if epoch is not None else 'Final'}):\\n\n",
        "    {report}\\n\n",
        "    {cm_report}\n",
        "    \"\"\"\n",
        "\n",
        "        print(final_report)\n",
        "        with open(\"classification_report.txt\", \"a\") as f:\n",
        "            f.write(final_report + \"\\n\")\n",
        "\n",
        "        f1 = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(num_classes)], output_dict=True, zero_division=0)['weighted avg']['f1-score']\n",
        "\n",
        "        return f1, all_preds, all_labels\n",
        "\n",
        "    def create_test_sets(test_dataset, num_sets=10, subset_size=0.9):\n",
        "        \"\"\"\n",
        "        Splits the test set into `num_sets` subsets, each containing `subset_size` proportion\n",
        "        of the data for each label, for Monte Carlo cross validation (MCCV)\n",
        "        \"\"\"\n",
        "        label_0_indices = [i for i, item in enumerate(test_dataset) if item[-1] == 0]\n",
        "        label_1_indices = [i for i, item in enumerate(test_dataset) if item[-1] == 1]\n",
        "        label_2_indices = [i for i, item in enumerate(test_dataset) if item[-1] == 2]\n",
        "\n",
        "        num_label_0_samples = int(len(label_0_indices) * subset_size)\n",
        "        num_label_1_samples = int(len(label_1_indices) * subset_size)\n",
        "        num_label_2_samples = int(len(label_2_indices) * subset_size)\n",
        "\n",
        "        test_sets = []\n",
        "        for _ in range(num_sets):\n",
        "            subset_label_0_indices = random.sample(label_0_indices, num_label_0_samples)\n",
        "            subset_label_1_indices = random.sample(label_1_indices, num_label_1_samples)\n",
        "            subset_label_2_indices = random.sample(label_2_indices, num_label_2_samples)\n",
        "\n",
        "            subset_indices = subset_label_0_indices + subset_label_1_indices + subset_label_2_indices\n",
        "            random.shuffle(subset_indices)\n",
        "\n",
        "            subset = Subset(test_dataset, subset_indices)\n",
        "            test_sets.append(subset)\n",
        "\n",
        "        return test_sets\n",
        "\n",
        "    def evaluate_on_multiple_test_sets(model, test_sets, num_classes=3, version=None):\n",
        "        \"\"\"\n",
        "        Evaluates the model on multiple test sets and calculates the average performance and standard deviations.\n",
        "        \"\"\"\n",
        "        all_reports = []\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        for i, test_set in enumerate(test_sets):\n",
        "            dataloader = DataLoader(test_set, batch_size=default_batch_size)\n",
        "            f1, preds, labels = generate_classification_report(model, dataloader, num_classes, version=version, split_name=f\"Test Set {i+1}\")\n",
        "            all_reports.append(classification_report(labels, preds, target_names=[str(i) for i in range(num_classes)], output_dict=True, zero_division=0))\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "        metrics = {}\n",
        "        for class_idx in range(num_classes):\n",
        "            class_str = str(class_idx)\n",
        "            metrics[f'precision_{class_str}'] = [report[class_str]['precision'] for report in all_reports]\n",
        "            metrics[f'recall_{class_str}'] = [report[class_str]['recall'] for report in all_reports]\n",
        "            metrics[f'f1-score_{class_str}'] = [report[class_str]['f1-score'] for report in all_reports]\n",
        "            metrics[f'support_{class_str}'] = [report[class_str]['support'] for report in all_reports]\n",
        "\n",
        "        metrics['macro_avg_precision'] = [report['macro avg']['precision'] for report in all_reports]\n",
        "        metrics['macro_avg_recall'] = [report['macro avg']['recall'] for report in all_reports]\n",
        "        metrics['macro_avg_f1-score'] = [report['macro avg']['f1-score'] for report in all_reports]\n",
        "        metrics['macro_avg_support'] = [report['macro avg']['support'] for report in all_reports]\n",
        "\n",
        "        metrics['weighted_avg_precision'] = [report['weighted avg']['precision'] for report in all_reports]\n",
        "        metrics['weighted_avg_recall'] = [report['weighted avg']['recall'] for report in all_reports]\n",
        "        metrics['weighted_avg_f1-score'] = [report['weighted avg']['f1-score'] for report in all_reports]\n",
        "        metrics['weighted_avg_support'] = [report['weighted avg']['support'] for report in all_reports]\n",
        "\n",
        "        results = {}\n",
        "        for metric_name, values in metrics.items():\n",
        "            results[metric_name + \"_avg\"] = np.mean(values)\n",
        "            results[metric_name + \"_std\"] = np.std(values)\n",
        "\n",
        "        final_report = \"Averaged performance across all test sets:\\n\"\n",
        "        for metric_name, value in results.items():\n",
        "            if \"_avg\" in metric_name:\n",
        "                std_name = metric_name.replace(\"_avg\", \"_std\")\n",
        "            if std_name in results:\n",
        "                final_report += f\"{metric_name}: {value:.4f} +/- {results[std_name]:.4f}\\n\"\n",
        "\n",
        "        print(final_report)\n",
        "        with open(\"classification_report.txt\", \"a\") as f:\n",
        "            f.write(final_report + \"\\n\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    class BertClassifier(nn.Module, PyTorchModelHubMixin):\n",
        "        def __init__(self, version, num_labels=3, freeze_bert=False, num_Bottid_categories=29):\n",
        "            super(BertClassifier, self).__init__()\n",
        "\n",
        "            if version == \"bert-uncased\":\n",
        "                self.bert = AutoModel.from_pretrained('google-bert/bert-base-uncased')\n",
        "            elif version == \"businessBERT\":\n",
        "                self.bert = AutoModel.from_pretrained('pborchert/BusinessBERT')\n",
        "            elif version == \"bottleneckBERT\":\n",
        "                self.bert = AutoModel.from_pretrained('colaguo/bottleneckBERTsmall')\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid model version: {version}\")\n",
        "\n",
        "            self.version = version\n",
        "\n",
        "            self.linear_features = nn.Sequential(\n",
        "                nn.Linear(13, 32),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "            self.linear_Bottid = nn.Sequential(\n",
        "                nn.Linear(num_Bottid_categories, 8),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "            self.cls_head = nn.Sequential(\n",
        "                nn.Linear(self.bert.config.hidden_size, 256),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "            self.linear_combined_layer = nn.Sequential(\n",
        "                nn.Linear(256 + 32 + 8, 32),\n",
        "                nn.ReLU())\n",
        "\n",
        "            self.final_classifier = nn.Linear(32, num_labels)\n",
        "\n",
        "            self.pooling = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "            if freeze_bert:\n",
        "                for param in self.bert.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "        def forward(self, input_ids, attention_mask, features, Bottid_encoded):\n",
        "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            last_hidden_state = outputs.last_hidden_state\n",
        "            pooled_output = self.pooling(last_hidden_state.permute(0, 2, 1)).squeeze(-1)\n",
        "\n",
        "            bert_output = self.cls_head(pooled_output)\n",
        "\n",
        "            linear_features_output = self.linear_features(features)\n",
        "            Bottid_output = self.linear_Bottid(Bottid_encoded)\n",
        "\n",
        "            combined_output = torch.cat((bert_output, linear_features_output, Bottid_output), dim=1)\n",
        "\n",
        "            linear_layer_output = self.linear_combined_layer(combined_output)\n",
        "\n",
        "            logits = self.final_classifier(linear_layer_output)\n",
        "            return logits, linear_layer_output\n",
        "\n",
        "    def load_tokenizer(version):\n",
        "        if version == \"bert-uncased\":\n",
        "            return AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
        "        elif version == \"businessBERT\":\n",
        "            return AutoTokenizer.from_pretrained('pborchert/BusinessBERT')\n",
        "        elif version == \"bottleneckBERT\":\n",
        "            return AutoTokenizer.from_pretrained('colaguo/bottleneckBERTsmall')\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid model version: {version}\")\n",
        "\n",
        "    ogpath = \"sept22_combined.csv\"\n",
        "    dataset = load_dataset('csv', data_files={'train': \"/content/drive/MyDrive/BERTearningsdata/\" + \"train_\" + ogpath, 'test': \"/content/drive/MyDrive/BERTearningsdata/\" +\"test_\" + ogpath})\n",
        "\n",
        "    train_df = pd.read_csv(\"/content/drive/MyDrive/BERTearningsdata/\" + \"train_\" + ogpath)\n",
        "    test_df = pd.read_csv(\"/content/drive/MyDrive/BERTearningsdata/\" + \"test_\" + ogpath)\n",
        "    test_df.loc[test_df['label'] > 2, 'label'] = 2\n",
        "\n",
        "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "    encoder.fit(train_df[['Bottid']])\n",
        "    train_encoded = encoder.transform(train_df[['Bottid']]).toarray()\n",
        "    test_encoded = encoder.transform(test_df[['Bottid']]).toarray()\n",
        "\n",
        "    feature_names = [f\"Bottid_{i}\" for i in range(train_encoded.shape[1])]\n",
        "\n",
        "    train_encoded_df = pd.DataFrame(train_encoded, columns=feature_names)\n",
        "    test_encoded_df = pd.DataFrame(test_encoded, columns=feature_names)\n",
        "\n",
        "    train_df = pd.concat([train_df, train_encoded_df], axis=1)\n",
        "    test_df = pd.concat([test_df, test_encoded_df], axis=1)\n",
        "\n",
        "    train_df = train_df.drop('Bottid', axis=1)\n",
        "    test_df = test_df.drop('Bottid', axis=1)\n",
        "\n",
        "    dataset['train'] = dataset['train'].from_pandas(train_df)\n",
        "    dataset['test'] = dataset['test'].from_pandas(test_df)\n",
        "\n",
        "    def truncate_dataset(dataset):\n",
        "        k = round(len(dataset)*0.99)\n",
        "        random_indices = random.sample(range(len(dataset)), k)\n",
        "        return dataset.select(random_indices)\n",
        "\n",
        "    dataset = {k: truncate_dataset(v) for k, v in dataset.items()}\n",
        "\n",
        "    def tokenize_function(examples, tokenizer):\n",
        "        return tokenizer(examples[\"paragraph\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "    class CustomDataset(Dataset):\n",
        "        def __init__(self, dataset, Bottid_categories=29):\n",
        "            self.dataset = dataset\n",
        "            self.Bottid_categories = Bottid_categories\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.dataset)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = self.dataset[idx]\n",
        "            input_ids = torch.tensor(item['input_ids'])\n",
        "            attention_mask = torch.tensor(item['attention_mask'])\n",
        "            label = torch.tensor(item['label'], dtype=torch.long)\n",
        "            features = torch.tensor([item['year'], item['word_count'], item['scarcity'], item['nonuniform_progress'], item['performance_constraints'], item['user_heterogeneity'], item['cognitive'], item['external'], item['internal'], item['coordination'], item['transactional'], item['technical'], item['demand']], dtype=torch.float)\n",
        "\n",
        "            Bottid_encoded = torch.tensor([item[f\"Bottid_{i}\"] for i in range(self.Bottid_categories)], dtype=torch.float)\n",
        "\n",
        "            return input_ids, attention_mask, features, Bottid_encoded, label\n",
        "\n",
        "    def train_and_evaluate(model, train_dataloader, val_dataloader, optimizer, epochs, loss_fn, supcon_loss_fn, supcon_weight, patience=4, num_classes=3, version=None, test_sets=None):\n",
        "        model.to(device)\n",
        "        best_f1 = 0.0\n",
        "        patience_counter = 0\n",
        "        best_epoch = 0\n",
        "        output_dir = \"model_output\"\n",
        "        best_model_state = None\n",
        "\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            total_ce_loss = 0\n",
        "            total_supcon_loss = 0\n",
        "\n",
        "            for batch in train_dataloader:\n",
        "                input_ids, attention_mask, features, Bottid_encoded, labels = [t.to(device) for t in batch]\n",
        "                model.zero_grad()\n",
        "\n",
        "                logits, embeddings = model(input_ids, attention_mask, features, Bottid_encoded)\n",
        "\n",
        "                ce_loss = loss_fn(logits, labels)\n",
        "\n",
        "                normalized_embeddings = nn.functional.normalize(embeddings, p=2, dim=1)\n",
        "                supcon_loss = supcon_loss_fn(normalized_embeddings, labels)\n",
        "\n",
        "                loss = ce_loss + supcon_weight * supcon_loss\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                total_ce_loss += ce_loss.item()\n",
        "                total_supcon_loss += supcon_loss.item()\n",
        "\n",
        "            avg_train_loss = total_loss / len(train_dataloader)\n",
        "            avg_ce_loss = total_ce_loss / len(train_dataloader)\n",
        "            avg_supcon_loss = total_supcon_loss / len(train_dataloader)\n",
        "\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for batch in val_dataloader:\n",
        "                    input_ids, attention_mask, features, Bottid_encoded, labels = [t.to(device) for t in batch]\n",
        "                    logits, _ = model(input_ids, attention_mask, features, Bottid_encoded)\n",
        "                    val_loss += loss_fn(logits, labels).item()\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_dataloader)\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f} (CE: {avg_ce_loss:.4f}, SupCon: {avg_supcon_loss:.4f}), Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "            f1_score,_,_ = generate_classification_report(model, val_dataloader, num_classes, epoch=epoch+1, version=version, split_name=\"Val\")\n",
        "\n",
        "            if f1_score > best_f1:\n",
        "                best_f1 = f1_score\n",
        "                best_epoch = epoch + 1\n",
        "                patience_counter = 0\n",
        "                best_model_state = model.state_dict()\n",
        "                print(f\"New best F1 score: {best_f1:.4f} at epoch {epoch+1}.\")\n",
        "\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "\n",
        "        if best_model_state is not None:\n",
        "            model.load_state_dict(best_model_state)\n",
        "            model_filename = f\"model_output/model_version_{version}.pth\"\n",
        "            torch.save(model.state_dict(), model_filename)\n",
        "            print(f\"Best model (version {version}) saved to {model_filename} with F1 {best_f1:.4f}\")\n",
        "\n",
        "            if test_sets is not None:\n",
        "                print(\"Evaluating on multiple test sets...\")\n",
        "                evaluate_on_multiple_test_sets(model, test_sets, num_classes=num_classes, version=version)\n",
        "                print(\"Evaluation on multiple test sets complete.\")\n",
        "\n",
        "        print(f\"Training completed. Best F1 score: {best_f1:.4f} achieved at epoch {best_epoch}.\")\n",
        "        return best_f1\n",
        "\n",
        "    # Main loop\n",
        "    for version in version_list:\n",
        "        print(f\"\\n----- Running with {version} -----\")\n",
        "\n",
        "        tokenizer = load_tokenizer(version)\n",
        "        tokenized_datasets = {split: data.map(lambda examples: tokenize_function(examples, tokenizer), batched=True) for split, data in dataset.items()}\n",
        "        train_dataset = tokenized_datasets[\"train\"]\n",
        "        test_dataset = tokenized_datasets[\"test\"]\n",
        "\n",
        "        num_Bottid_categories = train_encoded.shape[1]\n",
        "        train_data = CustomDataset(train_dataset, Bottid_categories=num_Bottid_categories)\n",
        "        test_data = CustomDataset(test_dataset, Bottid_categories=num_Bottid_categories)\n",
        "\n",
        "        test_sets = create_test_sets(test_data)\n",
        "\n",
        "        train_labels = [item['label'] for item in train_dataset]\n",
        "        label_counts = Counter(train_labels)\n",
        "        print(\"Original label distribution:\", label_counts)\n",
        "\n",
        "        min_count = min(label_counts.values())\n",
        "\n",
        "        train_data_loader = DataLoader(train_data, batch_size=default_batch_size, shuffle=True)\n",
        "        normalized_weights = torch.tensor([1.0, 2, 1.3])\n",
        "        loss_fn = nn.CrossEntropyLoss(weight=normalized_weights.to(device), label_smoothing=0.1)\n",
        "\n",
        "        supcon_loss_fn = losses.SupConLoss(temperature=supcon_temperature)\n",
        "\n",
        "        model = BertClassifier(version, num_labels=3, num_Bottid_categories=num_Bottid_categories).to(device)\n",
        "\n",
        "        train_dataloader = train_data_loader\n",
        "        val_dataloader = DataLoader(test_data, batch_size=default_batch_size)\n",
        "\n",
        "        # Standard Adam optimizer\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=default_lr)\n",
        "\n",
        "        train_and_evaluate(model, train_dataloader, val_dataloader, optimizer, epochs=num_epochs, loss_fn=loss_fn, supcon_loss_fn=supcon_loss_fn, supcon_weight=supcon_weight, num_classes=3, version=version, test_sets=test_sets)\n",
        "\n",
        "        evaluate_on_multiple_test_sets(model, test_sets, num_classes=3, version=version)\n",
        "        val_dataloader = DataLoader(test_data, batch_size=default_batch_size)\n",
        "        generate_classification_report(model, val_dataloader, num_classes=3, version=version)\n",
        "\n",
        "        # COMPUTE AND SAVE FEATURE IMPORTANCE\n",
        "        print(\"\\n----- Computing Feature Importance -----\")\n",
        "        importance_dict = compute_feature_importance(model, val_dataloader, tokenizer, num_features=13, num_Bottid_categories=num_Bottid_categories)\n",
        "\n",
        "        # Save to Google Drive\n",
        "        save_path = \"/content/drive/MyDrive/BERTearningsdata/\"\n",
        "        df_features, df_bottid = plot_feature_importance(importance_dict, FEATURE_NAMES, save_path, version)\n",
        "\n",
        "        print(f\"\\nTop 5 Most Important Numerical Features:\")\n",
        "        print(df_features.head())\n",
        "        print(f\"\\nTop 5 Most Important Bottid Categories:\")\n",
        "        print(df_bottid.head())"
      ],
      "metadata": {
        "id": "IwCGCkTINGyz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "c8b63e6fd6274b30832b0bad335a4c7e",
            "bfadaf82cb784707aaa4d1f80de100a2",
            "986be3bf16ab46ed8e09f4744b134c8d",
            "a4196d380bdd4ea8a9d94d23dacef9ca",
            "43682361065e46c49015e622ab02f8ca",
            "e3b10b2fb4b74c06bbea04b5ec672281",
            "adb9c29d672e4940bb32ae6d7ca88089",
            "8a80afe433724a79b6f670afa0bb17d1",
            "38bf38b7e5cf4e998db16ef29fcc7e88",
            "7c291fc65e5747d1915b8aae05abfd7e",
            "527a491b0bb84bf399b749f521914352",
            "0d90cd26ad23481b9bb5619ec81debe7",
            "4917b2dae613402c8cfd9431244085a7",
            "593f7d7fdeb94293975e4a63f07a006d",
            "6090444398ab4391be2724a215094c21",
            "75259fadab574e598b63b872ccdb39b7",
            "5b1b0b79b7874921abcdd5fb2ab56765",
            "3391c78387ef4838bf089e794aa724e0",
            "98631da21550469fbbc52e47a11a898a",
            "a3a9b2d9e80843ecb245ddf68355083d",
            "b6452fdbedca46d991c90162b632c7fa",
            "364852579f8f464eb6c9aacf36dabfe1"
          ]
        },
        "outputId": "ebd89a76-e3f4-44c9-8c18-772d211f8f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "----- Running with bottleneckBERT -----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5582 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8b63e6fd6274b30832b0bad335a4c7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2393 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d90cd26ad23481b9bb5619ec81debe7"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}